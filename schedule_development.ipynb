{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f28ccb2-36d2-4aab-a894-174e5d688533",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Week 1 (Thurs 2/2/23): Introduction to Module,  refresher \n",
    "\n",
    "## Presentation:\n",
    "- how will module be taught\n",
    "- how will module be assessed\n",
    "- schedule\n",
    "- expectations\n",
    "- resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39667a89-df02-41b2-b75f-79b8c00ae294",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Practical Activity: Refreshing the supervised machine learning workflow\n",
    "\n",
    "\n",
    "## Intended Learning Outcomes\n",
    "Refresher on:\n",
    "- the basic supervised Machine Learning Workflow\n",
    "- handling missing data\n",
    "- handling unbalanced datasets\n",
    "- estimating of model accuracy\n",
    "- making principled comparisons between trained models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1deb0a-779d-43ca-b5bc-3fcd943f5b7e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Self-Directed Study:\n",
    "1. Complete and prepare simple report for next week and post to blackboard wiki\n",
    "2.  Read a book chapter/ section on cnn's \n",
    "- could be, for example,[this ten page overview from arXiv]( https://arxiv.org/pdf/1511.08458.pdf) \n",
    "- or something else you find on the web\n",
    "- videos are fine, it's always good to  get practice in judging what is trustworthy.\n",
    "3. Read [this blog](https://jmyao17.github.io/Statistics/Nonparametric_Statistical_Significance_Tests.html) about how to do Non-Parametric Null Hypothesis Significancce Tests in python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36cab94-cbe4-4e1d-b67a-225735e842f5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Week 2 (Thurs 9/2/23): Convolutional Neural networks\n",
    "\n",
    "## Slides: What is convolution\n",
    "- What is convolution:  \n",
    "  basic idea;     \n",
    "  historical & mathematical background\n",
    "- Comparing Convolution Networks with Fully Connected Networks:\n",
    "  (Avoiding over-fitting by not being fully connected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6b938c-5b0e-4528-8164-02bd8fb11d01",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Practical activities - in groups of 3\n",
    "- exploring range of online tutorials describing training basic ConvNets on the CIFAR10 dataset.\n",
    "- working in small groups\n",
    "- hands on activities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e3cb35-7080-4368-9914-29a2962ae127",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Self-directed study: \n",
    "- How do you decide when to stop training a CNN and how does keras support this?\n",
    "\n",
    "- read chapter 14 of  [Aurélien Géron (2022) Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow, 3rd Edition.](https://uwe.primo.exlibrisgroup.com/view/action/uresolver.do?operation=resolveService&package_service_id=1544167050007511&institutionId=7511&customerId=7510&VE=true)  Available free to read online via the reading list or  from library if this link doesn't work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bd3c31-148e-4791-a798-398f0dc058c5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Week 3 (Thurs 16/2/23): Convnets and effects of uncertainty.\n",
    "Thurs 16/2/23\n",
    "### Data augmentation,\n",
    "- what is it?\n",
    "- what does keras support?\n",
    "- how do you decide what is valid?\n",
    "- what could you do yourself?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fe8eab-ccde-4a14-920d-a3e7e06cd53b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### practical activity\n",
    "Using the celeb faces data set  pick 5 people and train classifiers to recogtnise their faces using no augmentation, or different types of augmentation. \n",
    "Questions to investigate:\n",
    "1. Which of these are valid transformations for human faces?:\n",
    " - horizontal shifts\n",
    " - vertical shifts\n",
    " - rotation\n",
    " - horizontal flips\n",
    " - vertical flips\n",
    "To do this investigation using appropriate scientific method, treat each of these as a hypothesis to be tested. Take a number of observations (e.g. accuracy of trained model) for each case (e.g. using horizontal flips vs not using horizontal flips) then compare the meana results and use appropriate statistcal tests to determine whethe the results are statistically significanrtly differernt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ed7b15-d894-4357-9596-ec2bc53becc4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### class discussion\n",
    "does data augmentation provide a away of addressing:\n",
    "- ethical concerns about under-representation of certain groups\n",
    "- safety concerns for example wrt autonomous vehicles\n",
    "\n",
    "### self directed study\n",
    "Read paper on things like permutation testing to assess impact of protected characteristics  \n",
    "\n",
    "In group prepare 5 minute talk on an architecture for pre-trained images e.g. resnet, vgg, inception, mobilenet ...\n",
    "focussing on what is the new idea e.g. modularisation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8753b3d-1add-40ee-a809-79042ca4690a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Week 4 (Thurs 23/2/23): Transfer Learning\n",
    "\n",
    "## Presentation: what is tranfer learning and why would we want to do it:\n",
    "- The general idea: features useful in more than one context,\n",
    " -- train on successively harder problems (denoising)\n",
    " -- train on\n",
    "- training directly can take massies of computational effort: resuse this\n",
    "  -- large pretrained language models: BERT, Lambda, gpt3 \n",
    "  -- large vision models:   MobileNet, coco etc for visual problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285c6863-a210-45ed-b390-0460b67c5549",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Practical activity\n",
    "1. Download this [good tensorflow tutorial](https://www.tensorflow.org/tutorials/images/transfer_learning) with lots of examples of how to do the 'plumbing' using tensorflow built-in functions here: \n",
    " \n",
    "2.  Activity: read through and run that tutorial. In particular note how:\n",
    "  - there is a neat way of creating a test and validation set\n",
    "  - when they do the second step of fine-tuning they restart training from epoch 10 not zero (useful syntax)\n",
    "3. Then use the ideas from that notebook to take the CNN that you trained on the CIFAR data set in week 2,\n",
    "- freeze everything below the flatten() layer\n",
    "- and then add a new head and train it to classify the MNIST dataset. \n",
    "- Compare how long that takes to learn, and how effectively it does so,  \n",
    "  with training a CNN with the same configuration from scratch.\n",
    "\n",
    "### Self-directed Study:\n",
    "Read [article on curriculum learning](https://ieeexplore-ieee-org.ezproxy.uwe.ac.uk/document/9392296) (or get link from reading list) in reinforcement learning and be prepared to discuss whether it is a form of transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad615043-d316-4813-a07f-b1a0ff0d2af0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Week 5 Recurrent Neural networks\n",
    "Thurs 2/3/23\n",
    "\n",
    "## Activity: Class presentations on different CNN architectures\n",
    "- aim is to get peer feedback on presentation skills\n",
    "## Slides: \n",
    "- language processing into a sequence-to-sequence problem\n",
    "- time series problems\n",
    "- LSTM\n",
    " \n",
    " ### practical activities\n",
    " - build LSTM for a time series data set\n",
    " - how do we deal with missing data?\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ea5ee8-dbd8-4080-8589-5df70f98d2a7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    " # Week 6 (Thurs 9/3/23): NLP &Autoencoders\n",
    "   \n",
    " ## Presentation\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9abf38-3ed0-49c6-b89c-838634197a93",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    " ## Week 7 (Thurs 16/3/23): Large Language Models\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ec51d2-9669-4274-aeeb-909127cbb6c8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    " # Week 8 (Thurs 23/3/23): Reinforcement Learning\n",
    " \n",
    " ## Guest Lecture: Mihai Ancar \n",
    " ## Practical Activities: Coursework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec80f6a-4637-41c7-ba9b-1408a93fe36c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    " ## Week 9 (Thurs 30/3/23): Advances in optimisation metaheuristics \n",
    " \n",
    " ## Presentation\n",
    " - noise\n",
    " - multi-objective optimisation\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50160965-38ff-4529-a63e-729583071894",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    " \n",
    " ## Week 10 (Thursday 20/4/23): Hybrids of different Optimisation/ ML approaches\n",
    " \n",
    " - Guest lecture from Larry on Surrogate assisted optimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bc6219-06b5-484c-ac05-5aeced2c44ea",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    " \n",
    " # Week 11 (Thursday 27/4/23): Active Learning\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1febdc1f-ed93-4eca-b1a4-7c57ecc9d233",
   "metadata": {},
   "source": [
    "# Week 12: Groupwork Presentations\n",
    "Thursday 4/5/23 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fa032d-b78f-4993-ad55-19e1cdf31c2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py10",
   "language": "python",
   "name": "py10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
