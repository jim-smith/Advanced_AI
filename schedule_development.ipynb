{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5419022-ddeb-450c-a53d-2118f748c3fe",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Advanced Artificial Intelligence Module schedule 2024-25\n",
    "Note that content may change in response to the student cohort's interests and progress.\n",
    "\n",
    "<div style=\"color:black;background:lightpink; width:400px\"><h3>Portfolio Deadline will be 1st May</h3></div>\n",
    "\n",
    "## Week 1 : Introduction to Module,  refresher\n",
    "### Week commencing 27/1/25\n",
    "\n",
    "<div style=\"color:blue\"><h3>Presentation Lead: All</h3></div>\n",
    "\n",
    "### W1 Presentation:\n",
    "- how will module be taught and assessed\n",
    "- schedule\n",
    "- expectations\n",
    "- resources\n",
    "\n",
    "### W1 Practical Activity: \n",
    "- Refreshing the supervised machine learning workflow\n",
    "- Individual work comparing different ML algorithms for a given dataset\n",
    "- followed by class discussion of what a report should look like\n",
    "\n",
    "### W1 Assessment Timeline: Introduction of group project\n",
    "- Description of case study options\n",
    "- Opportunity to ask questions\n",
    "\n",
    "### W1 Intended Learning Outcomes\n",
    "1. Introduction to Module\n",
    "2. Refresher on:\n",
    "- the basic supervised Machine Learning Workflow\n",
    "- handling missing data\n",
    "- handling unbalanced datasets\n",
    "- estimating of model accuracy\n",
    "- **making principled comparisons between trained models**\n",
    "\n",
    "\n",
    "\n",
    "### W1 Self-Directed Study:\n",
    "1. Complete and prepare simple report for next week and post to blackboard wiki\n",
    "2.  Read a book chapter/ section on cnn's \n",
    "- could be, for example,[this ten page overview from arXiv]( https://arxiv.org/pdf/1511.08458.pdf) \n",
    "- or something else you find on the web\n",
    "- videos are fine, it's always good to  get practice in judging what is trustworthy.\n",
    "3. Read [this blog](https://jmyao17.github.io/Statistics/Nonparametric_Statistical_Significance_Tests.html) about how to do Non-Parametric Null Hypothesis Significancce Tests in python.\n",
    "\n",
    "\n",
    "## Week 2: Convolutional Neural networks\n",
    "### Week commencing 3/2/25\n",
    "<div style=\"color:blue\"><h3>Presentation Lead:Jim</h3></div>\n",
    "\n",
    "### W2 Presentation: What is convolution\n",
    "- What is convolution:  the basic idea, historical & mathematical background\n",
    "- An example of interactive AI: evolving filter networks for image segmentatation\n",
    "- Comparing Convolution Networks with Fully Connected Networks for end-to-end learning.\n",
    "\n",
    "### W2 Practical activity: \n",
    "- Comparing online resources for hands-on experience of building CNNs\n",
    "- Working in small groups to follow  tutorials from different sources, and compare  their value to you as learners.\n",
    "\n",
    "### W2 Assessment Timeline: Group formation\n",
    "- opportunity to propose groups of peers to work with\n",
    "- opportunity to ask questions about suitability of alternative projects\n",
    "\n",
    "### W2 Intended Learning Outcomes\n",
    "1. Understanding of\n",
    "- The basic concept of convolution in signal processing and machine learning\n",
    "- Convolutional Neural Networks for image classification\n",
    "2. Experience of using materials such as tutorials from various common sources and adapting them to new purposes. \n",
    "\n",
    "### W2 Self-directed study: \n",
    "- How do you decide when to stop training a CNN and how does keras support this?\n",
    "- Read chapter 14 of  [Aurélien Géron (2022) Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow, 3rd Edition.](https://uwe.primo.exlibrisgroup.com/view/action/uresolver.do?operation=resolveService&package_service_id=1544167050007511&institutionId=7511&customerId=7510&VE=true)  \n",
    "  Available free to read online via the reading list or  from library if this link doesn't work.\n",
    "  \n",
    "\n",
    "## Week 3: Convnets and effects of uncertainty.\n",
    "### Week commencing 10/2/25\n",
    "<div style=\"color:blue\"><h3>Presentation Lead:Jim</h3></div>\n",
    "\n",
    "### W3 Presentation: Data augmentation,\n",
    "- what is it, when *could* and *should* you think about using it?\n",
    "- what does keras support it?\n",
    "- how do you decide what are valid transformations?\n",
    "- what could you do yourself?\n",
    "\n",
    "### W3 Practical Activity: Using data augmentation in face recognition\n",
    "- Designing and conducting experiments to test the impact of different ways of changing images.  \n",
    "- Class discussion of how this could be used to address ethical and practical concerns of machine learning.\n",
    "\n",
    "### W3 Assessment Timeline: Finalised groups and projects\n",
    "- Groups finalised.\n",
    "- groups doing 'non-standard' projects discuss expectations with tutors.\n",
    "- each group  uploads project descriptor and 'Minimum Viable Product'.\n",
    "\n",
    "### W3 Intended Learning Outcomes\n",
    "1. Understanding of the role that noise inevitably plays in data capture\n",
    "2. Experience of some of the *'tricks of the trade'* for improving deep neural network training.\n",
    "3. Experience of using different data augmentation packages within Keras\n",
    "4. Refresher on good practice for comparing experiments/ hyper-parameter combinbations.\n",
    "\n",
    "### W3 Self directed study\n",
    "1. Read the blog posts linked in the practical notebook about batch normalisation and dropout.\n",
    "\n",
    "2. Explore the following sites to see whether you think are   more glossily presented, or fundamentally more thorough\"\n",
    "  - [google's take on fairness as part of Responsible AI](https://ai.google/responsibilities/responsible-ai-practices/?category=fairness) and explore some of the resources they provide. Do they seem than:\n",
    "  - [Apple's overview](https://machinelearning.apple.com/research?page=1&domain=Fairness) or the overview present\n",
    "  - [Facebook's overview](https://ai.facebook.com/blog/how-were-using-fairness-flow-to-help-build-ai-that-works-better-for-everyone/)\n",
    "  - [open ai's work on images](https://openai.com/blog/reducing-bias-and-improving-safety-in-dall-e-2/)  \n",
    "    they didn't seem to have a single page that covered language and vision models.  \n",
    "\n",
    "\n",
    "## Week 4: Transfer Learning\n",
    "### Week commencing 17/2/25\n",
    "\n",
    "### W4 Class Discussion: Corporations and Responsible AI\n",
    "- feedback from the reading/research I asked to do last week from last week \n",
    "\n",
    "<div style=\"color:blue\"><h3>Presentation Lead:Jim</h3></div>\n",
    "\n",
    "### W4 Presentation: what is transfer learning and why would we want to do it:\n",
    "- The general idea: features useful in more than one context, so:\n",
    "  - train on successively harder problems (de-noising)\n",
    "  - train on related problems where more data is available\n",
    "- training directly can take masses of computational effort: re-use this!\n",
    "  - large pretrained language models: BERT, Lambda, gpt3/4/5... \n",
    "  - large vision models:   MobileNet, coco etc for visual problems\n",
    "\n",
    "### W4 Practical activity\n",
    "- Starting with this [good tensorflow tutorial](https://www.tensorflow.org/tutorials/images/transfer_learning) \n",
    "- and then building on the ideas and techniques to conduct a range of experiments using transfer learning to repurpose CNNs built in previous weeks, looking at the effects of different mechanisms \n",
    "\n",
    "### W4 Assessment Timeline: ongoing design & lit review\n",
    "- opportunity for groups to get feedback on their choices of methods to compare\n",
    "\n",
    "### W4 Intended Learning Outcomes\n",
    "1. Understanding of the basic concept of transfer learning \n",
    "2. Hands-on experience of how it is applied in practice.\n",
    "3. Experience of working with keras pipeline and dataset classes\n",
    "\n",
    "### W4 Self-directed Study:\n",
    "1. Read [article on curriculum learning](https://ieeexplore-ieee-org.ezproxy.uwe.ac.uk/document/9392296) (or get link from reading list) in reinforcement learning and be prepared to discuss whether it is a form of transfer learning\n",
    "2. Contribute to class wikis comparing the keras and pytorch ecosystems for:\n",
    "   2a. Handling large dataflows (e.h. pytorch dataloaderrs and datasets vs keras equivalents)\n",
    "   2b. the types of pre-trained networks available, focussing on how easy it is to\n",
    "        - check how recently they have been updated/maintained, \n",
    "        - find (up to date) examples/documentation of \n",
    "           - how to use different models\n",
    "           - how to choose between different models\n",
    "   \n",
    "   \n",
    "\n",
    "## Week 5 new: Advanced network architectures: RESNETS and U-Nets\n",
    "### Week commencing 24/2/25\n",
    "\n",
    "### W5 Class discussion: \n",
    "1. *Is curriculum learning in RL just another form of transfer learning?*\n",
    "2. Should availability of models determine your choice of pytorch vs keras?\n",
    "\n",
    "\n",
    "<div style=\"color:blue\"><h3>Presentation Lead:Aina</h3></div>\n",
    "\n",
    "### W5 Presentation: Res(idual)nets and U-Nets\n",
    "1. What is the *Vanishing gradient* problem \n",
    "   and what is the trick that has led to the 2016 Resnet architecture:\n",
    "   - showing how to create truly deep neural networks\n",
    "   - becoming the most cited Deep Learning paper of the 21st century?\n",
    "   - and probably the most influential on society \n",
    "      (since Large Language Models  all use *residual blocks* in their transformers)\n",
    "2. How does the U-Net architecture let us go from\n",
    "   - *image-to-label* processing (e.g. convolutional networks with fully-connected \"heads\")  \n",
    "     to \n",
    "   - *image-to-image* processing - for example segmentation, Generative AI for images\n",
    "   \n",
    "### W5 Practical activities\n",
    "- complete previous workbooks\n",
    "\n",
    "### W5 Assessment Timeline: Feedback on initial design\n",
    "- Opportunity to ask questions\n",
    "\n",
    "### W5 Self-directed study\n",
    "- prepare informal presentations on project methodology. and choice of packages. \n",
    "   e.g. tensorflow vs keras vs. ... if using Deep Learning.\n",
    "\n",
    "## Week 6: Recurrent Neural networks\n",
    "### Week commencing 3/3/25\n",
    "<div style=\"color:blue\"><h3>Presentation Lead:XXX</h3></div>\n",
    "\n",
    "### W6 Presentation: \n",
    "- time series problems \n",
    "- statistical methods: ARIMA family of algorithms\n",
    "- Recurrent Architectures e.g. LSTM\n",
    "\n",
    "\n",
    "### W6 Practical activities\n",
    "- Class presentations on different companies' attitudes to ethical AI  \n",
    "- build LSTM for univariate and multivariate time series data set: \n",
    "- regression e.g.  \n",
    "   https://archive.ics.uci.edu/ml/datasets/Air+Quality   \n",
    "   or https://www.kaggle.com/datasets/sumanthvrao/daily-climate-time-series-data\n",
    "- comparison of architectures:   \n",
    "    MLP with time window   vs.  1-D CNN  vs.  LSTM\n",
    "\n",
    "### W6 Assessment Timeline: groups self-directed working\n",
    "- discussion with tutors\n",
    "- Feedback on initial methodology\n",
    "\n",
    "### W6 Intended Learning Outcomes\n",
    "1. Feedback on presentation skills\n",
    "2. Understanding of:\n",
    "  - Time series problems (classification and regression)\n",
    "  - Recurrent Neural Networks\n",
    "3. Further experience of how different packages support data workflows and pipelining\n",
    "\n",
    "### W6 Self-directed study:\n",
    "1. Read this article [G.So: Should We Abandon LSTM for CNN?](https://medium.com/ai-ml-at-symantec/should-we-abandon-lstm-for-cnn-83accaeb93d6)  as quite nice take on how to respond to reported findings in an open-minded way.   \n",
    "  Particularly relevant since the pace of *\"sensational new findings...\"* apearing in papers/blogs seems to be increasing.\n",
    "2. Group exercise tagging movie reviews\n",
    "\n",
    "## Week 7: Natural Language Processing (NLP)\n",
    "### Week commencing 10/3/25\n",
    "<div style=\"color:blue\"><h3>Presentation Lead:Elisa?</h3></div>\n",
    "\n",
    "### W7 Presentation:\n",
    " - elements of NLP: tokenisation, parts of speech, tagging, named entity and intent recognition.\n",
    " - rule-based systems, Bayesian approaches\n",
    " - word/sentence embeddings and semantic mapping.\n",
    " \n",
    "\n",
    "### W7 Practical activity and self-directed study\n",
    "- sentiment classification on IMDB dataset\n",
    "- Over weeks 6,7 and 8 you should aim to work through the first 5 workbooks from the module ML for Language and Vision\n",
    "\n",
    "### W7 Assessment Timeline: groups self-directed working\n",
    "- Opportunity to ask questions\n",
    "\n",
    "### W7 Learning Outcomes\n",
    "1. Understanding of the:\n",
    "- main statistical approaches to natural language processing, \n",
    "- role of different forms of pre-processing used for text\n",
    "2. Hands on experience of text pre-processing using contemporary toolkits such as nltk and spacey\n",
    "\n",
    "## Week 8: Neural approaches to NLP\n",
    "### Week commencing 17/3/25\n",
    "<div style=\"color:blue\"><h3>Presentation Lead:XXX</h3></div>\n",
    "\n",
    "### W8 Presentation:\n",
    "- recurrent approaches for sequence-to-sequence modelling\n",
    "- encoder-decoders & other architectures.\n",
    "- large language models and transfer learning\n",
    " \n",
    "\n",
    "### W8 Practical Activities and Self-directed study\n",
    "- continuing series of workbooks started in week 7\n",
    " \n",
    "### W8 Assessment Timeline: groups self-directed working\n",
    "\n",
    " \n",
    "### W8 Intended Learning Outcomes\n",
    "1. Understanding of contemporary approaches NLP and language modelling.\n",
    " \n",
    "\n",
    "## Week 9 Transformer Architectures\n",
    "### Week commencing 24/3/25\n",
    "<div style=\"color:blue\"><h3>Presentation Lead:Aina</h3></div>\n",
    "\n",
    "### W9 Presentation: Transformer Architectures\n",
    "\n",
    "\n",
    "### W9 Practical Activities and Self-Directed study: \n",
    "- complete the language modelling tasks started in week 7.\n",
    "- an activity using using [openai ml explainer](https://beta.openai.com/playground/p/default-ml-ai-tutor?model=text-davinci-003)\n",
    "\n",
    "### W9 Assessment Timeline: Formative feedback session\n",
    "Groups should come prepared to  informally present their:\n",
    "- proposed solution\n",
    "- proposed performance metrics\n",
    "- proposed methodology for evaluating their solution  \n",
    "  and comparing it to 'off-the-shelf' algorithms.\n",
    "\n",
    "### W9 Intended Learning Outcomes\n",
    "1. Understanding of transformer architectures\n",
    "2. Completed experience of working with Natural Language Processing\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "## Weeks 10-12: Research Lectures & Industry Talks\n",
    "\n",
    "\n",
    "| module week | starts on date|\n",
    "|-------|-------------|\n",
    "| 10 | 31/3 |\n",
    "|break | 7/4|\n",
    "|break | 14/4|\n",
    "|break |21/4|\n",
    "| 11 |28/4|\n",
    "| 12  | 01/05|\n",
    "|-------|-------|\n",
    "\n",
    "\n",
    "We aim to have talks from external industrial speakers   \n",
    "alongside presentations on current/ recent UWE research projects  from this indicative list: \n",
    "- Hybrids of different optimisation/ ML/ knowledge-based algorithms\n",
    "- Surrogate Model optimisation (Guest lecture from Prof. Larry Bull) \n",
    "- Assessing risks of bias and privacy-leakage  in ML trained on people's data\n",
    "- Reservoir Computing\n",
    "- Federated Learning\n",
    "- Active and Interactive Machine Learning\n",
    " \n",
    "### W10-12 Practical Activity: \n",
    "- working on Coursework\n",
    "\n",
    "### W10-12 Assessment Timeline: Formative feedback session\n",
    " \n",
    "### W10-12 Intended Learning Outcomes\n",
    "- Understanding of the different ways that the complementary strengths of different AI techniques can be combined. \n",
    "- An understanding of different ways in which effective human-machine teaming can be designed.\n",
    "- An understanding of how to work with ethical standards such as the [ICO AI & Data Protection Toolkit](https://ico.org.uk/for-organisations/uk-gdpr-guidance-and-resources/artificial-intelligence/guidance-on-ai-and-data-protection/ai-and-data-protection-risk-toolkit/) \n",
    "\n",
    "\n",
    "## Week 13 : Groupwork Presentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35937d83-b7dd-4914-b000-758f1dc0bd65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aienv",
   "language": "python",
   "name": "aienv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
