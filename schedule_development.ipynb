{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e161cf8-c26e-4384-b7af-915618e30f52",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Week 1: Introduction to Module,  refresher \n",
    "Thurs 2/2/23\n",
    "## Presentation:\n",
    "- how will module be taught\n",
    "- how will module be assessed\n",
    "- schedule\n",
    "- expectations\n",
    "- resources\n",
    "\n",
    "\n",
    "## Activity:\n",
    "1. Download the Palmer penguins data set and then compare the performance of:\n",
    " - k-Nearest Neighbours\n",
    " - Decision Tree Classifier\n",
    " - Random Forest\n",
    " - a multi-layer perceptron\n",
    " \n",
    "You will need to think about: data normalisation, handling missing data,feature processing, how you estimate classifier accuracy, how you select the hyper-parameters for different algorithms, and how much data you really have.\n",
    "\n",
    "We will spend the last 15 minutes of the session discussing how you have tackled this task.\n",
    "\n",
    "### Data set\n",
    "Download the dataset penguins_size from https://www.kaggle.com/datasets/parulpandey/palmer-archipelago-antarctica-penguin-data?resource=download&select=penguins_size.csv\n",
    "\n",
    "This data has 344 records and seven features:\n",
    "- Species (use this as the label to be predicted)\n",
    "- Island\n",
    "- culmen_length_mm\n",
    "- culmen_depth_mm\n",
    "- flipper_length_mm\n",
    "- body_mass_g\n",
    "- sex\n",
    "\n",
    "Use the kaggle page, or the page created by the original authors (resource\n",
    "here https://allisonhorst.github.io/palmerpenguins/articles/intro.html - in R)\n",
    "to understand what the data is capturing.\n",
    "\n",
    "\n",
    "## Intended Learning Outcomes\n",
    "Refresher on:\n",
    "- the basic supervised Machine Learning Workflow\n",
    "- handling missing data\n",
    "- handling unbalanced datasets\n",
    "- estimating of model accuracy\n",
    "- making principled comparisons between trained models\n",
    "\n",
    "## Self-Directed Study:\n",
    "- complete and prepare simple report for next week and post to blackboard wiki\n",
    "- book chapter/ section on cnn's and one on NHST\n",
    "- could be, for example, https://arxiv.org/pdf/1511.08458.pdf\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b32c66a-e3ad-4374-b3f5-642134d5209f",
   "metadata": {},
   "source": [
    "# Week 2: Convolutional neural networks\n",
    "Thurs 9/2/23\n",
    "## Slides: Recap on ### Keras/ tensorflow\n",
    "\n",
    "### CNN Motivation 1:  \n",
    "- Old fashioned image processing via kernels\n",
    "- Convolutional filters offer ways of (i) automating kernel choice,  \n",
    "  (ii) building more complex  features(layers), \n",
    "  (iii) generalising over presence of artefacts anywhere in the image\n",
    "\n",
    "### CNN Motivation 2:\n",
    "- Avoiding over-fitting by not being fully connected\n",
    "\n",
    "## Practical activities - in groups of 3 exploring resources for training basic ConvNets on the CIFAR10 dataset\n",
    "1. Group spends five minutes finding a different notebook/explalantion then\n",
    "- one person looks at [keras tutorial](https://www.tensorflow.org/tutorials/images/cnn) \n",
    "- second looks at [Machine Learning mastery blog]:(https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/)\n",
    " (stopping at the section \"How to Develop an Improved Model\")\n",
    "\n",
    "- third looks at the other resource they identified such as [this kaggle tutorial](https://www.kaggle.com/code/amyjang/tensorflow-cifar10-cnn-tutorial)\n",
    "\n",
    "2. All of them run through their workbooks and note down:\n",
    "- how easy to follow and self-contained was the explanation?\n",
    "- what sort of accuracy were they getting?\n",
    "- how was that accuracy merasured i.e. what metrics, train-test vs cross validation?\n",
    "- did the resource provide useful pointers for more things to explore?\n",
    "\n",
    "3. Group compares notes \n",
    "4. Class discussion\n",
    "\n",
    "### Self-directed study: \n",
    "- How do you decide when to stop training a CNN and how does keras support this?\n",
    "\n",
    "- read chapter 14 of  [Aurélien Géron (2022) Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow, 3rd Edition.](https://uwe.primo.exlibrisgroup.com/view/action/uresolver.do?operation=resolveService&package_service_id=1544167050007511&institutionId=7511&customerId=7510&VE=true)  Available free to read online via the reading list or  from library if this link doesn't work.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99e335c-6658-4a6b-9cc8-51fbd9b29f1c",
   "metadata": {},
   "source": [
    "## Week 3: Convnets and effects of uncertainty.\n",
    "Thurs 16/2/23\n",
    "### Data augmentation,\n",
    "what does keras support?\n",
    "how do you decide what is valid?\n",
    "what could you do yourself?\n",
    "\n",
    "### practical activity\n",
    "Using the celeb faces data set  pick 5 people and train classifiers to recogtnise their faces using no augmentation, or differentr types of augmentation. \n",
    "Questions to investigate:\n",
    "1. Which of these are valid transformations for human faces?:\n",
    " - horizontal shifts\n",
    " - vertical shifts\n",
    " - rotation\n",
    " - horizontal flips\n",
    " - vertical flips\n",
    "To do this investigation using appropriate scientific method, treat each of these as a hypothesis to be tested. Take a number of observations (e.g. accuracy of trained model) for each case (e.g. using horizontal flips vs not using horizontal flips) then compare the meana results and use appropriate statistcal tests to determine whethe the results are statistically significanrtly differernt.\n",
    "\n",
    "\n",
    "### class discussion\n",
    "does data augmentation provide a away of addressing:\n",
    "- ethical concerns about under-representation of certain groups\n",
    "- safety concerns for example wrt autonomous vehicles\n",
    "\n",
    "### self directed study\n",
    "Read paper on things like permutation testing to assess impact of protected characteristics  \n",
    "\n",
    "In group prepare 5 minute talk on an architecture for pre-trained images e.g. resnet, vgg, inception, mobilenet ...\n",
    "focussing on what is the new idea e.g. modularisation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5a615d-b2ed-4d25-9102-fd8630ececa4",
   "metadata": {},
   "source": [
    "# Week 4 Transfer Learning\n",
    "Thurs 23/2/23\n",
    "## Presentation: what is tranfer learning and why would we want to do it:\n",
    "- The general idea: features useful in more than one context,\n",
    " -- train on successively harder problems (denoising)\n",
    " -- train on\n",
    "- training directly cna take massies of computational effort: resuse this\n",
    "  -- large pretrained language models: BERT, Lambda, gpt3 \n",
    "  -- large vision models:   MobileNet, coco etc for visual problems\n",
    "\n",
    "## Practical activity\n",
    "- [Good tensorflow tutorial](https://www.tensorflow.org/tutorials/images/transfer_learning) with lots of examples of how to do the 'plumbing' using tensorflow built-in functions here: \n",
    " \n",
    "-  Activity: read through and run that tutorial. In particular note how:\n",
    "  - there is a neat way of creating a test and validation set\n",
    "  - when they do the second step of fine-tuning they restart training from epoch 10 not zero (useful syntax)\n",
    "- Then use the ideas from that notebook to take the CNN that you trained on the CIFAR data set in week 2, freeze everything below the flatten() layer and then add a new head and treain it to classifiy the MNIST dataset. Compare how long that takes to learn, and how effectively it does so, with training a CNN with the same configuraation from scratch.\n",
    "\n",
    "### Self-directed Study:\n",
    "Read [article on curriculum learning](https://ieeexplore-ieee-org.ezproxy.uwe.ac.uk/document/9392296) (or get link from reading list) in reinforcement learning and be prepared to discuss whether it is a form of transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad615043-d316-4813-a07f-b1a0ff0d2af0",
   "metadata": {},
   "source": [
    "# Week 5 Recurrent Neural networks\n",
    "Thurs 2/3/23\n",
    "\n",
    "## Activity: Class presentations on different CNN architectures\n",
    "- aim is to get peer feedback on presentation skills\n",
    "## Slides: \n",
    "- language processing into a sequence-to-sequence problem\n",
    "- time series problems\n",
    "- LSTM\n",
    " \n",
    " ### practical activities\n",
    " - build LSTM for a time series data set\n",
    " - how do we deal with missing data?\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ea5ee8-dbd8-4080-8589-5df70f98d2a7",
   "metadata": {},
   "source": [
    " # Week 6: NLP &Autoencoders\n",
    " Thurs 9/3/23  \n",
    " ## Presentation\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9abf38-3ed0-49c6-b89c-838634197a93",
   "metadata": {},
   "source": [
    " ## Week 7 Transfer Learning\n",
    " Thurs 16/3/23\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ec51d2-9669-4274-aeeb-909127cbb6c8",
   "metadata": {},
   "source": [
    " ## Week 8 Reinforcement Learning\n",
    " Thurs 23/3/23\n",
    " ### Guest Lecture Mihai Ancar \n",
    " ### Practical Activities \n",
    " ## Activity: Start Coursework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec80f6a-4637-41c7-ba9b-1408a93fe36c",
   "metadata": {},
   "source": [
    " ## Week 9 Advances in optimisation metaheuristics \n",
    " Thurs 30/3/23\n",
    " - noise\n",
    " - multi-objective optimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50160965-38ff-4529-a63e-729583071894",
   "metadata": {},
   "source": [
    " \n",
    " ## Week 10 Hybrids\n",
    " Thursday 20/4/23\n",
    " - Guest lecture from Larry on Surrogate assisted optimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bc6219-06b5-484c-ac05-5aeced2c44ea",
   "metadata": {},
   "source": [
    " \n",
    " # Week 11 Active Learning\n",
    " Thursday 27/4/23\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1febdc1f-ed93-4eca-b1a4-7c57ecc9d233",
   "metadata": {},
   "source": [
    "# Week 12: Groupwork Presentations\n",
    "Thursday 4/5/23 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fa032d-b78f-4993-ad55-19e1cdf31c2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py10",
   "language": "python",
   "name": "py10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
