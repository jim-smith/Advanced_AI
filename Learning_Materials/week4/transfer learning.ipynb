{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "787483c3-0e69-44be-8c62-5eaccbaa6b96",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Overview\n",
    "\n",
    "What is transfer learning?\n",
    "- why do it?\n",
    "- relationship to fine-tuning\n",
    "\n",
    "Relationship to pre-training\n",
    "- autoencoders/auto-associators\n",
    "- large Language models\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82919dfd-95ff-4b60-92aa-f97afbe2b33f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Transfer Learning in a sentence \n",
    "\n",
    "Transfer Learning is an approach to learning new problems that attempts to leverage learning done on _similar_ problems.\n",
    "\n",
    "|![balance bike](imgs/balance.jpg)] | Then ... | ![road bike](imgs/roadbike.jpg)| ... then|![motor bike](imgs/motorbike.jpg)|\n",
    "\n",
    "\n",
    "original images from wikimedia [balance bike](https://upload.wikimedia.org/wikipedia/commons/5/51/Wooden_Balance_Bike_for_Kids_oak_frame_with_flame_red_tires.jpg)\n",
    "[road bike](https://commons.wikimedia.org/wiki/File:Colnago_Extreme_C.jpg)\n",
    "[motor bike](https://commons.wikimedia.org/wiki/File:Five_children_on_a_motorcycle.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13becc3-28f0-4da1-ae19-2655f22f43a7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Let's unpack that a bit\n",
    "\n",
    "Let's assume we have some input space $\\mathcal{X}$\n",
    "- could be the space of all 256 x256x3 images\n",
    "- or could be 'bag of words' encoding for  sentences with some fixed vocabulary\n",
    "- or some other common set of metrics/features that define a set of objects/events\n",
    "\n",
    "and an output space \n",
    " - e.g.  $\\mathcal{Y}_1$= \\[horse, truck,person,...\\], or\n",
    " - $\\mathcal{Y}_2$= \\[cat,dog\\]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5cd1d16-5b1d-4cf6-9c83-0cebadc07c57",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "One view of transfer learning says that if we split a model $M_1$ into two parts  \n",
    "$M_{1,intermediate}$ and $M_{1,final}$  \n",
    "with an intermediate 'feature detection output space'  $\\mathcal{F}$  \n",
    "\n",
    "where $M_{1,intermediate}: \\mathcal{X} \\rightarrow \\mathcal{F}$   \n",
    "and $ M_{1,final}: \\mathcal{F} \\rightarrow \\mathcal{Y_1}$\n",
    "\n",
    "i.e. for an input $x$, $ M_1(x) = M_{1,final}( M_{1,intermediate}(x))$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2180145-f0e4-45fc-b160-0a411a8b38a3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "![Simple CNN architecture](./imgs/typical_cnn.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267b6b13-bc07-43ec-af7c-5fa6d40c9381",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "![Simple CNN architecture ashowing internediate and final models](./imgs/typical_cnn_annotated.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eec40bc-d029-4c94-a3a2-f58eb1eb0957",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "then provided there are some common elements between the tasks:\n",
    "\n",
    "- given a model $M_1 = M_{1,final} ( M_{1,intermediate} )$ trained to predict $M_1: \\mathcal{X} \\rightarrow \\mathcal{Y_1}$ \n",
    "\n",
    "- we can create a model for task 2 $M_2 = M_{2,final}( M_{1,intermediate})$  to predict $M_2: \\mathcal{X} \\rightarrow \\mathcal{Y_2}$\n",
    "  \n",
    "- and this may be **better**  ... in some sense \n",
    "\n",
    "- than trying to learn both $M_{2,final}$ and $M_{2,intermediate}$ from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60f857b-d4e9-4460-9f06-99468284bc82",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Aside: fine-tuning\n",
    "\n",
    "Fine-tuning approach says that it is better to learn the sequence:\n",
    "\n",
    "1. Train   $M_{1,final}$ and $M_{1,intermediate}$ simultaneously for task 1\n",
    "\n",
    "2. Make copy $M_{2,intermediate} = M_{1,intermediate}$\n",
    "\n",
    "2. Freeze $M_{2,intermediate}$ and adapt $M_{2,final}$ to get good accuracy\n",
    "\n",
    "3. Then adapt both $M_{2,intermediate}$ and $M_{2,final}$ simultaneously for last few bits of improvement\n",
    "\n",
    "Steps 1-3 are transfer learning, 4 is fine tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b289db-d165-4516-b0f8-73bb045cdb3e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Sounds great,    so when is it appropriate?\n",
    "\n",
    "| Scenario | Transfer Learning ? | Fine-tuning?| Why?|\n",
    "| ---|---|---|---|\n",
    "| New data set is small and task2 is  similar to task 1 | Yes | No | Risk of over-fitting |\n",
    "| New data set is large and task2 is  similar to task 1 | Yes  | Yes |\n",
    "| New data set is large and task 2 is different to task 2| No | No | Train from scratch|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571b6b94-0537-41f8-8246-10b1040d0dd4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Examples: lots of deep CNNs are available which were trained on ImageNet or CIFAR-100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9441a650-3b80-4c8c-ac04-e1227828f396",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "### Image-Net [homepage](https://image-net.org)\n",
    "Collection of >14m  images organised into >21k \"synonym-sets\" according to word-net hierarchy.\n",
    "- each labelled by several volunteers with different tags\n",
    "- >1m have bounding box information for artefacts\n",
    "- Good description from [papers with code]( https://paperswithcode.com/dataset/imagenet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6822659-a9bf-4ac6-a365-729bcb152fd2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### CoCo Common Objects in Context [homepage](https://cocodataset.org/#home)\n",
    "-  330k labelled images\n",
    "- but 1.5 million object instances from >80 imagenet classes\n",
    "-  contains more precisely segmented objects\n",
    "- ![example](https://cocodataset.org/images/detection-splash.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcb555a-1b7f-4697-9ffd-d1b753504750",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Issues?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aac628b-3906-4869-8b73-9adccc33c757",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Mapping input spaces (domains) between problems\n",
    "or how do I use $M_{1, intermediate}$ for problem 2 if $\\mathcal{X_1} \\neq \\mathcal{X_2}$\n",
    "\n",
    "Images:\n",
    "- resize, rescale, \n",
    "- simple if $|\\mathcal{X_1}| < |\\mathcal{X_2}|$ i.e. smaller images, one channel (b/w) vs 3 (rgb)\n",
    "- what if the opposite is true?  \n",
    "  - upscaling fairly well understood (e.g. SD to HD for tvs) \n",
    "  - pseudo colouring vs mapping gray scale to rgb. if task 1 has 3 channels and task 2 has 1\n",
    "\n",
    "Language:\n",
    "- can be problematic if the need to restrict vocabularies to a manageable size means words from task 2 not present in task 1\n",
    "  - e.g. medibert vs bert [medibert arXiv paper, Rasmi et al 2020](https://arxiv.org/abs/2005.12833)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826aa08a-0870-481f-a934-89bf14fa3c5a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### What if I don't have a nicely labelled dataset for task1 ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953abfc7-6029-44ae-b88d-f5fc28d2a733",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "<span style=\"color:red; font-size:24pt;\">That's where pre-training comes in ...</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222455e4-9f01-488d-9e32-1f830b38304d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Pretraining as a form of transfer learning\n",
    "\n",
    "### Put crudely: define a simple task to turn unsupervised  problem  into  a supervised  one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38412f9f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Example _de-noising autoencoders_<sup>1</sup>\n",
    "\n",
    "Takes the original idea of autoencoders as a pretraining step \n",
    ">One key ingredient to this success appears to be the use of an unsupervised training criterion to perform a layer-by-layer initialization: each layer is at first trained to produce a higher level (hidden) representation of the observed patterns, based on the representation it receives as input from the layer below, by optimizing a local unsupervised criterion. ... \\[then\\] a global fine-tuning of the modelâ€™s parameters is then performed using another training criterion appropriate for the task at hand.\n",
    "\n",
    "where the 'unsupervised criteria' is that you can reconstruct the input to a layer from its outputs,   \n",
    "and then adds to it the idea that partially corrupted versions of inputs should produce similar outputs.\n",
    "\n",
    "1: _Pascal Vincent, Hugo Larochelle, Yoshua Bengio, and Pierre-Antoine Manzagol. 2008. Extracting and composing robust features with denoising autoencoders. In Proceedings of the 25th international conference on Machine learning, pages 1096â€“1103. ACM._ [pdf link](https://www.cs.toronto.edu/~larocheh/publications/icml-2008-denoising-autoencoders.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9393eac4-e761-4ee1-a149-3dcfb08121c9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Example 2: Large Language models \n",
    "Most of these e.g. GPT, BERT etc. use pre-training a lot.\n",
    "\n",
    "For example, BERT uses a combination of two simple pre-training objectives:\n",
    "- a 'masked language model'  \n",
    "    - randomly blank out some words from input sentences \n",
    "    - simple output layer has to predict the  missing word.\n",
    "    - allows for training of a Bidirectional Transformer (more in next few weeks)\n",
    "- 'next sentence prediction'\n",
    "  - pass in a sentence and either:\n",
    "  - the next one (label= _IsNext_)\n",
    "  - a random sentence (_NotNext_)\n",
    "\n",
    "> [See Fig 1 in *BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding*, Devlin et al 2019](https://arxiv.org/pdf/1810.04805.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ef56f4-7bc5-4efc-91ee-cb17ae32270f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "79f41b8a-5202-45a0-95a7-db345feb8803",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Other related tasks: Curriculum learning\n",
    "An approach to Reinforcement Learning that uses progressively more complex tasks\n",
    " - either in simulation:\n",
    "   - bend\n",
    "   - walk\n",
    "   - run\n",
    "   - jump\n",
    "   - parkour!\n",
    "- or simulation $\\rightarrow$ reality\n",
    "\n",
    "Could use for supervised ML $\\rightarrow$ Generative Adversarial Networks "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6005d5df",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary\n",
    "1. Transfer Learning is really powerful, especially when you don't have much data\n",
    "\n",
    "2. There are links to _curriculum learning_ where you train model through a sequence of successively more complex tasks (widely used in Reinforcement Learning)  \n",
    "   There's a reading list article about this.\n",
    "   \n",
    "3. **It is not without its problems**  \n",
    "   Especially if the early problems \"bake-in\" unwanted bias.  \n",
    "   For example, in the image below 'synsets' are different occupations.\n",
    "\n",
    "   ![example of bias in imagenet](https://image-net.org/static_files/figures/demographcs_distribution.png)\n",
    "   [report on image-net bias](https://image-net.org/update-sep-17-2019.php)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ec7297",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "MLenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
