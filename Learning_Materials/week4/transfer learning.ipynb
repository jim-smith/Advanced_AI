{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "787483c3-0e69-44be-8c62-5eaccbaa6b96",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Overview\n",
    "\n",
    "What is transfer learning?\n",
    "- why do it?\n",
    "- relationship to fine-tuning\n",
    "\n",
    "Relationship to pre-training\n",
    "- autoencoders/auto-associators\n",
    "- large Language models\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82919dfd-95ff-4b60-92aa-f97afbe2b33f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Transfer Learning in a sentence \n",
    "\n",
    "Transfer Learning is an approach to learning new problems that attempts to leverage learning done on _similar_ problems.\n",
    "\n",
    "|![balance bike](imgs/balance.jpg)] | Then ... | ![road bike](imgs/roadbike.jpg)| ... then|![motor bike](imgs/motorbike.jpg)|\n",
    "\n",
    "\n",
    "original images from wikimedia [balance bike](https://upload.wikimedia.org/wikipedia/commons/5/51/Wooden_Balance_Bike_for_Kids_oak_frame_with_flame_red_tires.jpg)\n",
    "[road bike](https://commons.wikimedia.org/wiki/File:Colnago_Extreme_C.jpg)\n",
    "[motor bike](https://commons.wikimedia.org/wiki/File:Five_children_on_a_motorcycle.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13becc3-28f0-4da1-ae19-2655f22f43a7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Let's unpack that a bit\n",
    "\n",
    "Let's assume we have some input space $\\mathcal{X}$\n",
    "- could be the space of all 256 x256x3 images\n",
    "- or could be 'bag of words' encoding for  sentences with some fixed vocabulary\n",
    "- or some other common set of metrics/features that define a set of objects/events\n",
    "\n",
    "and an output space \n",
    " - e.g.  $\\mathcal{Y}_1$= \\[horse, truck,person,...\\], or\n",
    " - $\\mathcal{Y}_2$= \\[cat,dog\\]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5cd1d16-5b1d-4cf6-9c83-0cebadc07c57",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "One view of transfer learning says that if we split a model $M_1$ into two parts  \n",
    "$M_{1,intermediate}$ and $M_{1,final}$  \n",
    "with an intermediate 'feature detection output space'  $\\mathcal{F}$  \n",
    "\n",
    "where $M_{1,intermediate}: \\mathcal{X} \\rightarrow \\mathcal{F}$   \n",
    "and $ M_{1,final}: \\mathcal{F} \\rightarrow \\mathcal{Y_1}$\n",
    "\n",
    "i.e. for an input $x$, $ M_1(x) = M_{1,final}( M_{1,intermediate}(x))$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2180145-f0e4-45fc-b160-0a411a8b38a3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "![Simple CNN architecture](./imgs/typical_cnn.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267b6b13-bc07-43ec-af7c-5fa6d40c9381",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "![Simple CNN architecture ashowing internediate and final models](./imgs/typical_cnn_annotated.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eec40bc-d029-4c94-a3a2-f58eb1eb0957",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "then provided there are some common elements between the tasks:\n",
    "\n",
    "- given a model $M_1 = M_{1,final} ( M_{1,intermediate} )$ trained to predict $M_1: \\mathcal{X} \\rightarrow \\mathcal{Y_1}$ \n",
    "\n",
    "- we can create a model for task 2 $M_2 = M_{2,final}( M_{1,intermediate})$  to predict $M_2: \\mathcal{X} \\rightarrow \\mathcal{Y_2}$\n",
    "  \n",
    "- and this may be **better**  ... in some sense \n",
    "\n",
    "- than trying to learn both $M_{2,final}$ and $M_{2,intermediate}$ from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60f857b-d4e9-4460-9f06-99468284bc82",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Aside: fine-tuning\n",
    "\n",
    "Fine-tuning approach says that it is better to learn the sequence:\n",
    "\n",
    "1. Train   $M_{1,final}$ and $M_{1,intermediate}$ simultaneously for task 1\n",
    "\n",
    "2. Make copy $M_{2,intermediate} = M_{1,intermediate}$\n",
    "\n",
    "2. Freeze $M_{2,intermediate}$ and adapt $M_{2,final}$ to get good accuracy\n",
    "\n",
    "3. Then adapt both $M_{2,intermediate}$ and $M_{2,final}$ simultaneously for last few bits of improvement\n",
    "\n",
    "Steps 1-3 are transfer learning, 4 is fine tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b289db-d165-4516-b0f8-73bb045cdb3e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Sounds great,    so when is it appropriate?\n",
    "\n",
    "| Scenario | Transfer Learning ? | Fine-tuning?| Why?|\n",
    "| ---|---|---|---|\n",
    "| New data set is small and task2 is  similar to task 1 | Yes | No | Risk of over-fitting |\n",
    "| New data set is large and task2 is  similar to task 1 | Yes  | Yes |\n",
    "| New data set is large and task 2 is different to task 2| No | No | Train from scratch|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571b6b94-0537-41f8-8246-10b1040d0dd4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Examples: lots of deep CNNs are available which were trained on ImageNet or CIFAR-100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9441a650-3b80-4c8c-ac04-e1227828f396",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "### Image-Net [homepage](https://image-net.org)\n",
    "Collection of >14m  images organised into >21k \"synonym-sets\" according to word-net hierarchy.\n",
    "- each labelled by several volunteers with different tags\n",
    "- >1m have bounding box information for artefacts\n",
    "- Good description from [papers with code]( https://paperswithcode.com/dataset/imagenet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6822659-a9bf-4ac6-a365-729bcb152fd2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### CoCo Common Objects in Context [homepage](https://cocodataset.org/#home)\n",
    "-  330k labelled images\n",
    "- but 1.5 million object instances from >80 imagenet classes\n",
    "-  contains more precisely segmented objects\n",
    "- ![example](https://cocodataset.org/images/detection-splash.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcb555a-1b7f-4697-9ffd-d1b753504750",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Issues?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aac628b-3906-4869-8b73-9adccc33c757",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Mapping input spaces (domains) between problems\n",
    "or how do I use $M_{1, intermediate}$ for problem 2 if $\\mathcal{X_1} \\neq \\mathcal{X_2}$\n",
    "\n",
    "Images:\n",
    "- resize, rescale, \n",
    "- simple if $|\\mathcal{X_1}| < |\\mathcal{X_2}|$ i.e. smaller images, one channel (b/w) vs 3 (rgb)\n",
    "- what if the opposite is true?  \n",
    "  - upscaling fairly well understood (e.g. SD to HD for tvs) \n",
    "  - pseudo colouring vs mapping gray scale to rgb. if task 1 has 3 channels and task 2 has 1\n",
    "\n",
    "Language:\n",
    "- can be problematic if the need to restrict vocabularies to a manageable size means words from task 2 not present in task 1\n",
    "  - e.g. medibert vs bert [medibert arXiv paper, Rasmi et al 2020](https://arxiv.org/abs/2005.12833)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826aa08a-0870-481f-a934-89bf14fa3c5a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### What if I don't have a nicely labelled dataset for task1 ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953abfc7-6029-44ae-b88d-f5fc28d2a733",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "<span style=\"color:red; font-size:24pt;\">That's where pre-training comes in ...</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222455e4-9f01-488d-9e32-1f830b38304d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Pretraining as a form of transfer learning\n",
    "\n",
    "### Put crudely: define a simple task to turn unsupervised  problem  into  a supervised  one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38412f9f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Example _de-noising autoencoders_<sup>1</sup>\n",
    "\n",
    "Takes the original idea of autoencoders as a pretraining step \n",
    ">One key ingredient to this success appears to be the use of an unsupervised training criterion to perform a layer-by-layer initialization: each layer is at first trained to produce a higher level (hidden) representation of the observed patterns, based on the representation it receives as input from the layer below, by optimizing a local unsupervised criterion. ... \\[then\\] a global fine-tuning of the model’s parameters is then performed using another training criterion appropriate for the task at hand.\n",
    "\n",
    "where the 'unsupervised criteria' is that you can reconstruct the input to a layer from its outputs,   \n",
    "and then adds to it the idea that partially corrupted versions of inputs should produce similar outputs.\n",
    "\n",
    "1: _Pascal Vincent, Hugo Larochelle, Yoshua Bengio, and Pierre-Antoine Manzagol. 2008. Extracting and composing robust features with denoising autoencoders. In Proceedings of the 25th international conference on Machine learning, pages 1096–1103. ACM._ [pdf link](https://www.cs.toronto.edu/~larocheh/publications/icml-2008-denoising-autoencoders.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9393eac4-e761-4ee1-a149-3dcfb08121c9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Example 2: Large Language models \n",
    "Most of these e.g. GPT, BERT etc. use pre-training a lot.\n",
    "\n",
    "For example, BERT uses a combination of two simple pre-training objectives:\n",
    "- a 'masked language model'  \n",
    "    - randomly blank out some words from input sentences \n",
    "    - simple output layer has to predict the  missing word.\n",
    "    - allows for training of a Bidirectional Transformer (more in next few weeks)\n",
    "- 'next sentence prediction'\n",
    "  - pass in a sentence and either:\n",
    "  - the next one (label= _IsNext_)\n",
    "  - a random sentence (_NotNext_)\n",
    "\n",
    "> [See Fig 1 in *BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding*, Devlin et al 2019](https://arxiv.org/pdf/1810.04805.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ef56f4-7bc5-4efc-91ee-cb17ae32270f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "79f41b8a-5202-45a0-95a7-db345feb8803",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Other related tasks: Curriculum learning\n",
    "An approach to Reinforcement Learning that uses progressively more complex tasks\n",
    " - either in simulation:\n",
    "   - bend\n",
    "   - walk\n",
    "   - run\n",
    "   - jump\n",
    "   - parkour!\n",
    "- or simulation $\\rightarrow$ reality\n",
    "\n",
    "Could use for supervised ML $\\rightarrow$ Generative Adversarial Networks "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6005d5df",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary\n",
    "1. Transfer Learning is really powerful, especially when you don't have much data\n",
    "\n",
    "2. There are links to _curriculum learning_ where you train model through a sequence of successively more complex tasks (widely used in Reinforcement Learning)  \n",
    "   There's a reading list article about this.\n",
    "   \n",
    "3. **It is not without its problems**  \n",
    "   Especially if the early problems \"bake-in\" unwanted bias.  \n",
    "   For example, in the image below 'synsets' are different occupations.\n",
    "\n",
    "   ![example of bias in imagenet](https://image-net.org/static_files/figures/demographcs_distribution.png)\n",
    "   [report on image-net bias](https://image-net.org/update-sep-17-2019.php)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ec7297",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "MLenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
