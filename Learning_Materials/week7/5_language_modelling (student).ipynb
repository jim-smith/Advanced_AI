{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practical 5: Language Modelling\n",
    "\n",
    "Language models attempt to create a generalised long-term model of language. That is, a model that has learned the characteristics of the language it was trained on, such as grammar, punctuation, the relationship between words and so on. Typically, language models predict the next token of a sequence, given the previous tokens, or simply calculate the probability of a sequence of tokens. This can be implemented with a simple n-gram language model, but these are limited to predicting only sequences of n-grams (word combinations) observed within the training data.\n",
    "\n",
    "In contrast, ML language models are much more robust and capable of generating more varied and 'imaginative' texts. RNN are well suited to this task due to their sequential processing of input. However, modern stat-of-the-art language models, such as [GPT-3](https://openai.com/blog/gpt-3-apps/), typically use [Transformers](https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)). In either case LM are typically trained on very large natural language datasets, such as Wikipedia, Amazon reviews, Google books, or in our case Sherlock Holmes stories! Importantly, and similar to word vectors, once trained, the model of language that has been learned can be transfered to other downstream tasks, such as classification and translation.\n",
    "\n",
    "In the first part of this practical we will create two n-gram language models. The first will simply calculate the probability of an input sentence, given the training corpus. The second will generate the next word, given the previous words in a sequence.\n",
    "\n",
    "In the second part of this practical we will create an RNN language model using the complete works of [Sherlock Holmes by Sir Aurthur Conan Doyle](https://sherlock-holm.es/) as a training corpus. Then we will use the trained model to generate sentences in the style of Conan Doyle, and explore various different methods of sampling from the word probabilities generated by the model.\n",
    "\n",
    "The objectives of this practical are:\n",
    "1. Understand the key concepts of language modelling and evaluation: calculating the probability of a sentence or next token and calculating perplexity\n",
    "\n",
    "2. Introduce new ML techniques that are usefull for building large models: data generators, custom metrics, early stopping and checkpointing\n",
    "\n",
    "3. Compare and contrast different sampling methods, such as greedy, temperature and top-k"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 N-gram Language Models\n",
    "\n",
    "## 1.0 Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "from nltk import ngrams"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Probability of a sentence\n",
    "\n",
    "We can create simple language models using n-grams. Whether we are calculating the probability of a sequence, or trying to predict the next word, the first step is the same: calculate the probability of a word given the previous word (bi-gram), or words (tri-gram +).\n",
    "\n",
    "So, for each n-gram within the training corpus we need to calculate:\n",
    "\n",
    "$P(word|previous \\; words) = \\frac{count(previous \\; words, \\; word)}{count(previous \\; words)}$\n",
    "\n",
    "The language model is then effectively the set of n-gram probabilites that have been calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-grams: Counter({('this', 'is'): 3, ('is', 'a'): 2, ('i', 'love'): 2, ('love', 'my'): 2, ('a', 'dog'): 1, ('a', 'cat'): 1, ('my', 'cat'): 1, ('my', 'dog'): 1, ('is', 'my'): 1, ('my', 'name'): 1})\n",
      "Uni-grams: Counter({'this': 3, 'is': 3, 'my': 3, 'a': 2, 'dog': 2, 'cat': 2, 'i': 2, 'love': 2, 'name': 1})\n",
      "P(('is',)|this) = 1.0\n",
      "P(('a',)|is) = 0.6666666666666666\n",
      "P(('dog',)|a) = 0.5\n",
      "P(('is',)|this) = 1.0\n",
      "P(('a',)|is) = 0.6666666666666666\n",
      "P(('cat',)|a) = 0.5\n",
      "P(('love',)|i) = 1.0\n",
      "P(('my',)|love) = 1.0\n",
      "P(('cat',)|my) = 0.3333333333333333\n",
      "P(('love',)|i) = 1.0\n",
      "P(('my',)|love) = 1.0\n",
      "P(('dog',)|my) = 0.3333333333333333\n",
      "P(('is',)|this) = 1.0\n",
      "P(('my',)|is) = 0.3333333333333333\n",
      "P(('name',)|my) = 0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "# Define the corpus\n",
    "corpus = ['This is a dog', 'This is a cat', 'I love my cat', 'I love my dog', 'This is my name']\n",
    "\n",
    "# Count the unigrams and n-grams\n",
    "N = 2\n",
    "n_grams = []\n",
    "uni_grams = []\n",
    "for sent in corpus:\n",
    "    tokens = sent.lower().split()\n",
    "    n_grams.extend(list(ngrams(tokens, N)))\n",
    "    uni_grams.extend(tokens)\n",
    "\n",
    "n_gram_count = Counter(n_grams)\n",
    "print(f\"{N}-grams: {n_gram_count}\")\n",
    "uni_gram_count = Counter(uni_grams)\n",
    "print(f\"Uni-grams: {uni_gram_count}\")\n",
    "\n",
    "# Calculate the n-gram probabilities\n",
    "n_gram_probs = {}\n",
    "for n_gram in n_grams:\n",
    "    n_gram_probs[n_gram] = n_gram_count[n_gram] / uni_gram_count[n_gram[0]]\n",
    "    print(f\"P({n_gram[1:]}|{n_gram[0]}) = {n_gram_probs[n_gram]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have calculated the n-gram probabilities calculating the probability of a sentence is simply:\n",
    "\n",
    "1. Count the n-grams in the input sentence\n",
    "\n",
    "2. Find the product of all n-grams that exist within both the model and the input sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-grams: [('this', 'is'), ('is', 'my'), ('my', 'dog')]\n",
      "2-gram: ('this', 'is') probability: 1.0\n",
      "2-gram: ('is', 'my') probability: 0.333\n",
      "2-gram: ('my', 'dog') probability: 0.333\n",
      "Probablility of sentence \"This is my dog\" = 0.111\n"
     ]
    }
   ],
   "source": [
    "# Sentence to calculate probability of\n",
    "sentence = \"This is my dog\"\n",
    "\n",
    "# Count n-grams\n",
    "sentence_n_grams = list(ngrams([token.lower() for token in sentence.split()], N))\n",
    "print(f\"{N}-grams: {sentence_n_grams}\")\n",
    "\n",
    "# Calculate probability of sentence\n",
    "probability = 1\n",
    "# For each n-gram in sentence\n",
    "for n_gram in sentence_n_grams:\n",
    "\n",
    "    # If its probability is in the training corpus\n",
    "    if n_gram in n_gram_probs:\n",
    "        print(f\"{N}-gram: {n_gram} probability: {round(n_gram_probs[n_gram], 3)}\")\n",
    "\n",
    "        # Multiply the probability of the n-gram to the total probability\n",
    "        probability *= n_gram_probs[n_gram]\n",
    "\n",
    "print(f\"Probablility of sentence \\\"{sentence}\\\" = {round(probability, 3)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Probability of next word\n",
    "\n",
    "To calculate the probability of the next word in a sequence we need to build a language model in the same manner as before, by finding the probability of a word given the previous word(s):\n",
    "\n",
    "$P(word|previous \\; words) = \\frac{count(previous \\; words, \\; word)}{count(previous \\; words)}$\n",
    "\n",
    "Note that here we have added two special tokens, `<s>` signifies the start of a sentence and `</s>` the end. This is often useful when generating text because it provides a generic starting, and potentially end point, for the generation process. Otherwise you would always need to provide a starting token/word, such as 'I', and this would influence selection of the following tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2-grams: Counter({('<s>', 'i'): 2, ('i', 'am'): 2, ('am', 'sam'): 1, ('sam', '</s>'): 1, ('<s>', 'sam'): 1, ('sam', 'i'): 1, ('am', '</s>'): 1, ('i', 'do'): 1, ('do', 'not'): 1, ('not', 'like'): 1, ('like', 'green'): 1, ('green', 'eggs'): 1, ('eggs', 'and'): 1, ('and', 'ham'): 1, ('ham', '</s>'): 1})\n",
      "Uni-grams: Counter({'<s>': 3, 'i': 3, '</s>': 3, 'am': 2, 'sam': 2, 'do': 1, 'not': 1, 'like': 1, 'green': 1, 'eggs': 1, 'and': 1, 'ham': 1})\n",
      "P(('i',)|<s>) = 0.6666666666666666\n",
      "P(('am',)|i) = 0.6666666666666666\n",
      "P(('sam',)|am) = 0.5\n",
      "P(('</s>',)|sam) = 0.5\n",
      "P(('sam',)|<s>) = 0.3333333333333333\n",
      "P(('i',)|sam) = 0.5\n",
      "P(('am',)|i) = 0.6666666666666666\n",
      "P(('</s>',)|am) = 0.5\n",
      "P(('i',)|<s>) = 0.6666666666666666\n",
      "P(('do',)|i) = 0.3333333333333333\n",
      "P(('not',)|do) = 1.0\n",
      "P(('like',)|not) = 1.0\n",
      "P(('green',)|like) = 1.0\n",
      "P(('eggs',)|green) = 1.0\n",
      "P(('and',)|eggs) = 1.0\n",
      "P(('ham',)|and) = 1.0\n",
      "P(('</s>',)|ham) = 1.0\n"
     ]
    }
   ],
   "source": [
    "# Define the corpus\n",
    "corpus = ['<s> I am Sam </s>', '<s> Sam I am </s>', '<s> I do not like green eggs and ham </s>']\n",
    "\n",
    "# Calculate the unigram and n-gram counts\n",
    "N = 2\n",
    "n_grams = []\n",
    "uni_grams = []\n",
    "for sent in corpus:\n",
    "    tokens = sent.lower().split()\n",
    "    n_grams.extend(list(ngrams(tokens, N)))\n",
    "    uni_grams.extend(tokens)\n",
    "\n",
    "n_gram_count = Counter(n_grams)\n",
    "print(f\"{N}-grams: {n_gram_count}\")\n",
    "uni_gram_count = Counter(uni_grams)\n",
    "print(f\"Uni-grams: {uni_gram_count}\")\n",
    "\n",
    "# Calculate the n-gram probabilities\n",
    "n_gram_probs = {}\n",
    "for n_gram in n_grams:\n",
    "    n_gram_probs[n_gram] = n_gram_count[n_gram] / uni_gram_count[n_gram[0]]\n",
    "    print(f\"P({n_gram[1:]}|{n_gram[0]}) = {n_gram_probs[n_gram]}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have created the model, by calculating the n-gram probabilities, we can use it to generate text:\n",
    "\n",
    "1. First start with the seed tokens/text which will 'prompt' the model for the next token. In this case we can simply use the start of a sentence token (`<s>`).\n",
    "\n",
    "2. Loop until the end of sentence token (`</s>`) is generated, or a maximum sequence length is reached. At each step:\n",
    "\n",
    "    1. Find *all* the possible next tokens given the previous token.\n",
    "\n",
    "    2. Select the next token using the chosen sampling method.\n",
    "\n",
    "    3. Add the selected token to the generated text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Possible tokens: \n",
      "{'i': 0.6666666666666666, 'sam': 0.3333333333333333}\n",
      "Next token: i\n",
      "Possible tokens: \n",
      "{'am': 0.6666666666666666, 'do': 0.3333333333333333}\n",
      "Next token: am\n",
      "Possible tokens: \n",
      "{'sam': 0.5, '</s>': 0.5}\n",
      "Next token: sam\n",
      "Possible tokens: \n",
      "{'</s>': 0.5, 'i': 0.5}\n",
      "Next token: </s>\n",
      "Generated text: <s> i am sam </s>\n"
     ]
    }
   ],
   "source": [
    "# Set the seed text\n",
    "generated_text = \"<s>\"\n",
    "# Variable to hold the next token\n",
    "next_token = ''\n",
    "# Set the maximum sequence length\n",
    "max_seq_len = 10\n",
    "# Set the sampling method\n",
    "sampling_method = 'greedy'\n",
    "\n",
    "# While next token is not end of sentence and max sequence length is not reached\n",
    "i = 0\n",
    "while next_token != '</s>' and i < max_seq_len:\n",
    "\n",
    "    # Tokenize generated text\n",
    "    tokens = generated_text.lower().split()\n",
    "\n",
    "    possible_next_tokens = {}\n",
    "    # Find possible next tokens\n",
    "    for n_gram, prob in n_gram_probs.items():\n",
    "        # If last token of generated text is the first token of n-gram\n",
    "        if n_gram[0] == tokens[-1]:\n",
    "            # Add n-gram to possible next tokens\n",
    "            possible_next_tokens[n_gram[1]] = prob\n",
    "\n",
    "    print('Possible tokens: ')\n",
    "    print(possible_next_tokens)\n",
    "\n",
    "    # Select next token\n",
    "    # Greedy choice (highest probability)\n",
    "    if sampling_method == 'greedy':\n",
    "        next_token = list(sorted(possible_next_tokens.items(), key=lambda item: item[1]))[-1][0]\n",
    "\n",
    "    print(f'Next token: {next_token}\\n')\n",
    "\n",
    "    # Add next token to generated text\n",
    "    generated_text += ' ' + next_token\n",
    "    i += 1\n",
    "\n",
    "print('Generated text: ' + generated_text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Exercise: Different sampling methods\n",
    "\n",
    "The above algorithm uses a 'greedy' sampling method, which simply selects the most probable token from all possible next tokens. However, even with large sophisticated language models greedy sampling often results in generic and repetative text.\n",
    "\n",
    "1. Extend the code to add a few other sampling methods. For example:\n",
    "\n",
    "    1. 'eager', which selects the first possible token\n",
    "\n",
    "    2. 'random', which randomly selects from all possible tokens\n",
    "    \n",
    "    3. Or even better, 'weighted_random', which randomly selects from all possible tokens weighted by the token probability. This can be simply implemented using `np.random.choice()`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 RNN ('Sherlock') Language Models\n",
    "\n",
    "## 2.0 Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gensim.downloader as gen\n",
    "import tensorflow as tf\n",
    "from collections import Counter\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "%matplotlib inline\n",
    "\n",
    "# Set the directory to the data folder\n",
    "data_dir = os.path.join('..', 'data', 'sherlock')\n",
    "\n",
    "# # Spacy needs to install the language model also\n",
    "# # If you recieve an error, uncomment the following line and re-run the cell\n",
    "# # !python -m spacy download en_core_web_sm\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Load and pre-process data\n",
    "\n",
    "The data directory should contain the complete works of Sherlock Holmes as a set of text files. We will simply loop over each file, tokenise into sentences, lowercase all words and remove extra whitespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading texts from files: ['A Study in Scarlet.txt', 'His Last Bow.txt', 'The Adventures of Sherlock Holmes.txt', 'The Case-Book of Sherlock Holmes.txt', 'The Hound of the Baskervilles.txt', 'The Memoirs of Sherlock Holmes.txt', 'The Return of Sherlock Holmes.txt', 'The Sign of Four.txt', 'The Valley of Fear.txt']\n",
      "Number of sentences: 44016\n",
      "First 5 sentences: \n",
      "['a', 'study', 'in', 'scarlet', 'arthur', 'conan', 'doyle', 'table', 'of', 'contents', 'part']\n",
      "['i', 'mr.', 'sherlock', 'holmes', 'the', 'science', 'of', 'deduction', 'the', 'lauriston', 'garden', 'mystery']\n",
      "['what', 'john', 'rance', 'had', 'to', 'tell', 'our', 'advertisement', 'brings', 'a', 'visitor', 'tobias', 'gregson', 'shows', 'what', 'he', 'can', 'do', 'light']\n",
      "['in', 'the', 'darkness', 'part', 'ii']\n",
      "['on', 'the', 'great', 'alkali', 'plain', 'the', 'flower', 'of', 'utah', 'john', 'ferrier', 'talks', 'with', 'the', 'prophet', 'a', 'flight', 'for', 'life', 'the', 'avenging', 'angels', 'a', 'continuation', 'of', 'the', 'reminiscences', 'of', 'john', 'watson', ',', 'm.d.', 'the', 'conclusion', 'part']\n"
     ]
    }
   ],
   "source": [
    "print('Loading texts from files: ' + str(os.listdir(data_dir)))\n",
    "\n",
    "# Load the data\n",
    "sentences = []\n",
    "for file_name in os.listdir(data_dir):\n",
    "    with open(os.path.join(data_dir, file_name), 'r') as file:\n",
    "        doc = nlp(file.read().replace('\\n', ' '))\n",
    "\n",
    "        # Tokenize the sentences\n",
    "        for sent in doc.sents:\n",
    "            # Remove whitespace tokens and lowercase\n",
    "            tokens = [token.text.lower() for token in sent if not token.is_space]\n",
    "            # After tokenizing and removing whitespace, remove sentences with only one token\n",
    "            if len(tokens) > 1:\n",
    "                sentences.append(tokens)\n",
    "\n",
    "print('Number of sentences: ' + str(len(sentences)))\n",
    "print('First 5 sentences: ')\n",
    "for sent in sentences[0:5]:\n",
    "    print(sent)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the distribution of sentence lengths to determin how long the input sequences should be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the distribution of sentence lengths\n",
    "seq_lengths = [len(sent) for sent in sentences]\n",
    "sns.displot(seq_lengths, kind='hist')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a vocabulary\n",
    "\n",
    "Create a vocabulary as before. For language modelling, increasing the vocabulary size greatly increases the complexity of the task, because each output prediction is a word from the vocabulary. So a vocabulary size of 10k is effectively a classification problem with 10k classes! However, if the vocabulary is too small the model will not be able to learn a sufficient number of words to generate interesting/meaningfull text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 19724\n",
      "(0, <pad>) (1, <unk>) (2, <s>) (3, </s>) (4, ,) (5, .) (6, the) (7, \") (8, and) (9, i) (10, of) (11, to) (12, a) (13, that) (14, it) (15, in) (16, he) (17, was) (18, you) (19, his) (20, is) (21, had) (22, have) (23, my) (24, with) (25, ?) (26, as) (27, for) (28, at) (29, -) (30, which) (31, we) (32, but) (33, not) (34, me) (35, this) (36, be) (37, there) (38, him) (39, ') (40, said) (41, holmes) (42, 's) (43, from) (44, no) (45, on) (46, one) (47, upon) (48, so) (49, all) "
     ]
    }
   ],
   "source": [
    "def create_vocabulary(corpus, vocab_size=None, min_freq=1, special_tokens=None):\n",
    "\n",
    "    # Count the frequency of each token in the corpus\n",
    "    word_counter = Counter()\n",
    "    for sent in corpus:\n",
    "        word_counter.update(sent)\n",
    "\n",
    "    if min_freq > 1:\n",
    "        # Remove tokens that occur less than min_freq times\n",
    "        word_counter =  Counter({word: count for word, count in word_counter.items() if count >= min_freq})\n",
    "\n",
    "    # Create a vocabulary\n",
    "    vocab = []\n",
    "    vocab_size = len(word_counter) if vocab_size is None else vocab_size\n",
    "\n",
    "    # Add the special tokens to the vocabulary\n",
    "    if special_tokens and isinstance(special_tokens, list):\n",
    "        vocab.extend(special_tokens)\n",
    "    else:\n",
    "        special_tokens = []\n",
    "\n",
    "    # Add the vocab_size most common tokens to the vocabulary\n",
    "    vocab.extend([word for word, count in word_counter.most_common(vocab_size - len(special_tokens))])\n",
    "\n",
    "    return vocab\n",
    "\n",
    "# Create a vocabulary\n",
    "vocab = create_vocabulary(sentences, vocab_size=None, min_freq=1, special_tokens=['<pad>', '<unk>', '<s>', '</s>'])\n",
    "\n",
    "# Print the vocabulary\n",
    "print(\"Vocabulary size: \" + str(len(vocab)))\n",
    "for i, word in enumerate(vocab[:50]):\n",
    "    print(f'({str(i)}, {word})', end=' ')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Create a data generator\n",
    "\n",
    "For many NLP tasks, which require large training datasets, it is impractical or infeasible to pre-process the entier dataset beforhand. In most cases the pre-processing time could be very long, but more importantly the data would not fit in memory!\n",
    "\n",
    "Language modelling can be a good example of this. At each timestep we want to predict the next token in the sequence. So, for each sentence in our dataset we need to produce input sequences for each word in the sentence (+ the `<s>` and `</s>` tokens). For example, the sentence '*In the year 1878*' becomes:\n",
    "\n",
    "- `<s>`\n",
    "\n",
    "- `<s>` In\n",
    "\n",
    "- `<s>` In the\n",
    "\n",
    "- `<s>` In the year\n",
    "\n",
    "- `<s>` In the year 1886\n",
    "\n",
    "- `<s>` In the year 1886 `</s>`\n",
    "\n",
    "So, the ~41k sentences in the dataset become ~800k! Not only would this take much longer to process but also considerably more memory.\n",
    "\n",
    "To get around this problem we can use a Generator class (by subclassing a Keras Sequence class). A Generator *class* allow us to define how each batch of data is processed and this will be performed on-the-fly at runtime. A Generator *object* can be passed into `model.fit()` instead of lists/arrays of data (inputs and labels or x and y), and each batch will be 'consumed' by the model.\n",
    "\n",
    "In the `LMDataGenerator` class below the key method is `__getitem__()`, which defines how each batch of data should be processed. In this case the sentences are vectorised, the `<s>` and `</s>` tokens added and then padded with the `<pad>` token to the `max_seq_len`. Each time the function is called it returns the `batch_size` of input sequences and expected outputs (target token).\n",
    "\n",
    "Take some time to understand what the Generator class below is doing. Particularly the `__getitem__()` method.\n",
    "\n",
    "<div class = \"alert alert-block alert-info\"><b>Note:</b> We could perform all pre-processing within the data generator, such as tokenisation and lowercasing. However, for simplicity and to allow the creation of a vocabulary, here we only preform the step which greatly increase memory requirements.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches: 6246\n",
      "(128, 80)\n",
      "(128,)\n",
      "Input Sentence: <s> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Input Vector: [2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0]\n",
      "Target Word: we\n",
      "\n",
      "Input Sentence: <s> we <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Input Vector: [ 2 31  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0]\n",
      "Target Word: heard\n",
      "\n",
      "Input Sentence: <s> we heard <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Input Vector: [  2  31 148   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0]\n",
      "Target Word: the\n",
      "\n",
      "Input Sentence: <s> we heard the <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Input Vector: [  2  31 148   6   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0]\n",
      "Target Word: rattle\n",
      "\n",
      "Input Sentence: <s> we heard the rattle <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
      "Input Vector: [   2   31  148    6 2546    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0]\n",
      "Target Word: of\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class LMDataGenerator(tf.keras.utils.Sequence):\n",
    "    \"\"\"Custom data generator for language modeling.\"\"\"\n",
    "\n",
    "    def __init__(self, data, vocab, max_seq_len, batch_size, shuffle=True):\n",
    "        \n",
    "        self.data = data\n",
    "        self.vocab = vocab\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "        # Get the data indexes and shuffle\n",
    "        self.indexes = np.arange(len(self.data))\n",
    "        self.on_epoch_end()\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"Updates data after each epoch. Currently only shuffles data if shuffle=True.\"\"\"\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "        \n",
    "    def __len__(self):\n",
    "        \"\"\"Calculates the number of batches per epoch (num_tokens / batch_size).\"\"\"\n",
    "        sum = np.sum([len(sent) for sent in self.data])\n",
    "        return int(np.ceil(sum / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Generates a batch of data.\"\"\"\n",
    "\n",
    "        # Generate batch of inputs and outputs\n",
    "        batch_inputs, batch_outputs = [], []\n",
    "        i = 0\n",
    "        while i < self.batch_size:\n",
    "\n",
    "            # Get the sentence\n",
    "            sent = self.data[self.indexes[index]]\n",
    "\n",
    "            # Vectorise the sentences\n",
    "            vectorised_sent = [self.vocab.index(word) if word in self.vocab else self.vocab.index('<unk>') for word in sent]\n",
    "            # Add the start and end tokens\n",
    "            vectorised_sent = [self.vocab.index('<s>')] + vectorised_sent + [self.vocab.index('</s>')]\n",
    "\n",
    "            # Incrementally add each word in the vectorised sentence to the input batch\n",
    "            # Add the next word to the output batch\n",
    "            for j in range(1, len(sent) - 1):\n",
    "                batch_inputs.append(vectorised_sent[:j])\n",
    "                batch_outputs.append(vectorised_sent[j])\n",
    "\n",
    "                # Increment the batch counter\n",
    "                i += 1\n",
    "                if i >= self.batch_size:\n",
    "                    break\n",
    "            \n",
    "            # Increment the data index if we have not filled the batch\n",
    "            if len(batch_inputs) < self.batch_size:\n",
    "                index += 1 if index + 1 < len(self.data) else 0\n",
    "\n",
    "        # Pad the sentences to the max_seq_len\n",
    "        batch_inputs = pad_sequences(batch_inputs, maxlen=self.max_seq_len, padding='post', truncating='post', value=0.0)\n",
    "\n",
    "        # Conver input/outputs to numpy arrays\n",
    "        batch_inputs = np.array(batch_inputs)\n",
    "        batch_outputs = np.array(batch_outputs)\n",
    "        \n",
    "        return batch_inputs, batch_outputs\n",
    "\n",
    "# Set the maximum sequence length and batch size\n",
    "max_seq_len = 80\n",
    "batch_size = 128\n",
    "\n",
    "# Create a data generator\n",
    "data_generator = LMDataGenerator(sentences, vocab, max_seq_len=max_seq_len, batch_size=batch_size)\n",
    "\n",
    "# Print the number of batches\n",
    "print('Number of batches: ' + str(len(data_generator)))\n",
    "\n",
    "# Print the first examples\n",
    "inputs, outputs = data_generator[0]\n",
    "print(inputs.shape)\n",
    "print(outputs.shape)\n",
    "for i in range(5):\n",
    "    print('Input Sentence: ' + ' '.join([vocab[word] for word in inputs[i]]))\n",
    "    print('Input Vector: ' + str(inputs[i]))\n",
    "    print('Target Word: ' + str(vocab[outputs[i]]))\n",
    "    print()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Create an embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of embeddings: (19724, 300)\n",
      "[[ 0.          0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " [ 0.29745131 -0.58824459 -0.82285656 ... -0.42817501 -0.37204594\n",
      "  -0.31586437]\n",
      " [-0.92729657  0.40835539  0.5166385  ...  0.55271557 -0.60070922\n",
      "  -0.04791399]\n",
      " [-0.84890795 -0.99841716 -0.83168475 ...  0.67454524 -0.50529898\n",
      "   0.98968065]\n",
      " [-0.25538999 -0.25723001  0.13169    ... -0.23289999 -0.12226\n",
      "   0.35499001]]\n"
     ]
    }
   ],
   "source": [
    "# Set the embedding dimension\n",
    "embedding_dim = 300\n",
    "\n",
    "# Load the word embeddings\n",
    "glove_vectors = gen.load(\"glove-wiki-gigaword-\" + str(embedding_dim))\n",
    "\n",
    "# Generate the embedding matrix\n",
    "embedding_matrix = np.zeros((len(vocab), embedding_dim))\n",
    "for i, word in enumerate(vocab):\n",
    "    # Skip the padding token\n",
    "    if i == 0:\n",
    "        continue\n",
    "    \n",
    "    if word in glove_vectors:\n",
    "        embedding_matrix[i] = glove_vectors[word]\n",
    "    else:\n",
    "        embedding_matrix[i] = np.random.uniform(low=-1.0, high=1.0, size=embedding_dim)\n",
    "\n",
    "print('Shape of embeddings:', embedding_matrix.shape)\n",
    "print(embedding_matrix[:5])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Build the RNN Language Model\n",
    "\n",
    "The following cells define a simple LSTM language model, with similar architecture to those we have previously used: an embedding layer, followed by an LSTM layer, followed by a feed forward classification layer.\n",
    "\n",
    "However, here we additionaly define a custom Metric class, to calculate during training (by subclassing a Keras Metrics class). A custom metric can be used in addition to the loss and accuracy metrics we have already seen.\n",
    "\n",
    "In the `PerplexityMetric` class below we can define the Perplexity calculation for each timestep. Recall that perplexity is simply:\n",
    "\n",
    "$PPL(P|Q) = 2^{H(P|Q)}$\n",
    "\n",
    "Where $H(P|Q)$ is the entropy (loss) of the learned distribution Q given the actuall distribution P.\n",
    "\n",
    "Perplexity can be considered a measure of a language models uncertainty when predicting the next word and is often a more informative metric than loss alone. A Perplexity of 10, for example, can be interpreted as the model choosing (or being uncertain) between 10 words in that situation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerplexityMetric(tf.keras.metrics.Mean):\n",
    "    \"\"\"Custom metric for perplexity.\n",
    "    Adapted from: https://gist.github.com/Gregorgeous/dbad1ec22efc250c76354d949a13cec3\"\"\"\n",
    "    \n",
    "    def __init__(self, name='perplexity', **kwargs):\n",
    "        super().__init__(name=name, **kwargs)\n",
    "        self.cross_entropy = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False, reduction='none')\n",
    "    \n",
    "    def _calculate_perplexity(self, real, pred):\n",
    "        # Create a mask to ignore the padding tokens\n",
    "        mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "\n",
    "        # Calculate the loss/entropy\n",
    "        loss_ = self.cross_entropy(real, pred)\n",
    "\n",
    "        # Apply the mask\n",
    "        loss_ *= tf.cast(mask, dtype=loss_.dtype)\n",
    "\n",
    "        # Calculate the perplexity\n",
    "        mean_loss = tf.keras.backend.mean(loss_, axis=-1)\n",
    "        perplexity = tf.keras.backend.exp(mean_loss)\n",
    "        return perplexity\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        perplexity = self._calculate_perplexity(y_true, y_pred)\n",
    "        super().update_state(perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sherlock_lm\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 80)]              0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 80, 300)           5917200   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 512)               1665024   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 19724)             10118412  \n",
      "=================================================================\n",
      "Total params: 17,700,636\n",
      "Trainable params: 17,700,636\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Input layer takes in an integer vector of length max_seq_len\n",
    "inputs = tf.keras.Input(shape=(max_seq_len,), dtype=tf.int32)\n",
    "\n",
    "# Create the embedding layer\n",
    "embedding_layer = layers.Embedding(\n",
    "    input_dim=len(vocab),\n",
    "    output_dim=embedding_dim,\n",
    "    input_length=max_seq_len,\n",
    "    embeddings_initializer=tf.keras.initializers.Constant(embedding_matrix),\n",
    "    mask_zero=True,\n",
    "    trainable=True)(inputs)\n",
    "\n",
    "# Recurrent layer\n",
    "x = layers.LSTM(512, return_sequences=False)(embedding_layer)\n",
    "\n",
    "# Classification layers\n",
    "x = layers.Dropout(0.2)(x)\n",
    "outputs = layers.Dense(len(vocab), activation=\"softmax\")(x)\n",
    "\n",
    "# Compile the model\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs, name='sherlock_lm')\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\",  metrics=[PerplexityMetric()])\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and evaluate the model\n",
    "\n",
    "Here we train the model using `model.fit()`, as before, but with two key differences:\n",
    "\n",
    "1. Notice the `data_generator` object, that was previously instantiated, replaces the input and output (or x and y) lists/arrays.\n",
    "\n",
    "2. Two callbacks have been defined and passed to the fit function. Callbacks define code that is run after each training epoch or batch and can be useful for all kinds of purposes, such as saving training metrics to a file. In this case they are primarily intended to prevent overfitting.\n",
    "\n",
    "    1. `ModelCheckpoint` saves the model during training. Crutially, we can specify a metric to `monitor`, such as loss, and only save the model if the loss is *lower* than the previous best. In this way, even if the model overfits during training, causing the loss to increase, we can load the 'best' model learned during training.\n",
    "\n",
    "    2. `EarlyStopping` again allows for the monitoring of a training metric. In this case, in order to stop the training process if the metric shows no improvement for more than `patience` number of epochs. Thus, if we have reached a point where the model is beginning to overfit we can simply end the training process.\n",
    "\n",
    "<div class = \"alert alert-block alert-warning\"><b>Warning:</b> **Please do not run this cell on UWE machines/CSCT cloud!**<br>\n",
    "This training process can take a *very* long time! It could take many hours, depending on your hardware, and especially if you do not have a GPU.  <br>Instead please either run this notebook on Google Colab, or skip this cell and load one of the pre-trained models provided (below).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_chkptr = tf.keras.callbacks.ModelCheckpoint(\n",
    "    'sherlock_lm.h5',\n",
    "    monitor='loss',\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    mode='min',\n",
    "    save_freq='epoch')\n",
    "\n",
    "model_earlystp = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"loss\",\n",
    "    min_delta=0.01,\n",
    "    patience=5,\n",
    "    verbose=0,\n",
    "    mode=\"min\",\n",
    "    restore_best_weights=False)\n",
    "\n",
    "# Fit the model\n",
    "results = model.fit(data_generator, epochs=30, callbacks=[model_chkptr, model_earlystp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best loss: 2.815\n",
      "Best perplexity: 22.741\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Best loss: ' + str(round(min(results.history['loss']), 3)))\n",
    "print('Best perplexity: ' + str(round(min(results.history['perplexity']), 3)))\n",
    "\n",
    "# Plot the training loss and perplexity\n",
    "fig, ax = plt.subplots(1, 2, figsize=(8, 6), sharex=True)\n",
    "sns.lineplot(results.history['loss'], ax=ax[0])\n",
    "ax[0].set(xlabel='epoch', ylabel='loss')\n",
    "sns.lineplot(results.history['perplexity'], ax=ax[1])\n",
    "ax[1].set(xlabel='epoch', ylabel='perplexity')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Generating text\n",
    "\n",
    "Once the model is trained we can now use it to generate some text! First we should load the weights of the best model found during training. As previously discussed, due to the length of training time it is highly recommended you load one of the models provided:\n",
    "\n",
    "sherlock_lm.h5:\n",
    " - Vocabulary size = 19k\n",
    " - Max sequence length = 80\n",
    " - Embedding dimension = 300\n",
    " - LSTM units = 512\n",
    " - Epochs = ~30\n",
    " - Perplexity = 17.496\n",
    " - Loss = 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sherlock_lm\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 80)]              0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 80, 300)           5917200   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 512)               1665024   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 19724)             10118412  \n",
      "=================================================================\n",
      "Total params: 17,700,636\n",
      "Trainable params: 17,700,636\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "model.load_weights('sherlock_lm.h5')\n",
    "print(model.summary())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the model to generate text just as we did in section 1.2:\n",
    "\n",
    "1. First start with the seed tokens/text which will 'prompt' the model for the next token. In this case we can simply use the start of a sentence token (`<s>`).\n",
    "\n",
    "2. Loop until the end of sentence token (`</s>`) is generated, or a maximum sequence length is reached. At each step:\n",
    "\n",
    "    1. Vectorise and pad the sequence into the correct input format for the model.\n",
    "\n",
    "    2. Generate predictions to find the probilities over *all* tokens in the vocabulary, given the previous tokens.\n",
    "\n",
    "    2. Select the next token using the chosen sampling method.\n",
    "\n",
    "    3. Add the selected token to the generated text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated text:  <s>  \" i am sort to say that you have only been waiting for me at the last place , mr. holmes , \" said the secretary , \" you have had a word of my friend and mr. holmes , \" he said , taking the go by the maid 's eyes , and the blood - honourable terrible had been left as a wire to make it , i could see the planned drawback , and he left\n"
     ]
    }
   ],
   "source": [
    "# Set the seed text and next token to empty string\n",
    "seed_text = '<s> '\n",
    "next_token = \"\"\n",
    "\n",
    "# Set the sampling parameters\n",
    "sampling_method = \"temp_nucleus\"\n",
    "temperature = 0.15\n",
    "top_k = 20\n",
    "top_p = 0.9\n",
    "\n",
    "# Generate the next \n",
    "while next_token != \"</s>\" and len(seed_text.split()) < max_seq_len:\n",
    "\n",
    "    # Vectorise the sentences\n",
    "    input_sent = [vocab.index(word) if word in vocab else vocab.index('<unk>') for word in seed_text.split()]\n",
    "    # Pad the sentences to the max_seq_len\n",
    "    input_sent = pad_sequences([input_sent], maxlen=max_seq_len, padding='post', truncating='post', value=0.0)\n",
    "    input_sent = np.array(input_sent)\n",
    "    \n",
    "    # Generate predictions\n",
    "    predictions = model.predict(input_sent, verbose=0)\n",
    "\n",
    "    # Sample the next token\n",
    "    if sampling_method == \"greedy\":\n",
    "        # Get the token with the highest probability\n",
    "        predicted_token = np.argmax(predictions, axis=-1)\n",
    "\n",
    "    elif sampling_method == \"temperature\":\n",
    "        # Convert the predictions to logit space\n",
    "        predictions = np.log(predictions[0],  where=predictions[0] > 0)\n",
    "\n",
    "        # Apply softmax with temperature\n",
    "        predictions = np.exp(predictions / temperature) / np.sum(np.exp(predictions / temperature))\n",
    "\n",
    "        # Sample from the distribution\n",
    "        predicted_token = np.random.choice(len(vocab), 1, p=predictions)\n",
    "\n",
    "    # Convert the predicted token to a word\n",
    "    next_token = vocab[predicted_token[0]]\n",
    "    \n",
    "    # Add the predicted word to the seed text\n",
    "    seed_text += \" \" + next_token\n",
    "\n",
    "# Print the generated text\n",
    "print(\"Generated text: \", seed_text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Exercise: Different sampling methods\n",
    "\n",
    "Above Two sampling methods are defined, 'greedy' and 'temperature'.\n",
    "\n",
    "1. Extend the code to add a few other sampling methods discussed in the lecture:\n",
    "\n",
    "    1. 'top-k', which sorts tokens by probabilites and ignores anythin below the $k^{th}$ token\n",
    "\n",
    "    2. 'nucleus', which sets a value for p in the range [0, 1]. Once the cumulative probability of tokens reaches p the rest are ignored\n",
    "    \n",
    "    3. Or even better, 'temp_nucleus', which applies temperature to the probabilities and then applies nucleus sampling.\n",
    "\n",
    "    4. You can also try the 'weighted_random' that you developed previously.\n",
    "\n",
    "2. Experiment with the parameters `temperature`, `top_k` and `top_p`, for their respective sampling methods and see which produce the most natural text in the style of Sherlock Holmes."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.0 ('ML-L&V')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eda59365f9d652723e3bcf67739b9100ac1f6ab6ddfa121c8653940903b971a2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
