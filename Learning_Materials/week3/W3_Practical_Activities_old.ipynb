{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92d1575e-db9a-4452-8b62-45fe7ede2e98",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"width:400px, text-color:black\"> \n",
    "For this task we will use  the <a href=\"https://www.kaggle.com/datasets/nipunarora8/age-gender-and-ethnicity-face-data-csv?select=age_gender.csv\">age-gender-and-ethnicity-face dataset</a> which contains a number of images, each accompanied with features recording the age,  gender,  and ethnicity of the person in the image. This is a  version of the <a href=\"https://susanqq.github.io/UTKFace/\" > UTKface dataset</a>, modified to make it easer to load as one file.<br>\n",
    "Please note that\n",
    "    <ul>\n",
    "        <li><b>It happens not contain any people who self-identified as non-binary</b>. So gender is labelled as 0 (male) or 1 (female)</li>\n",
    "        <li> Ethicity is coded as an integer from 0 to 4, denoting White, Black, Asian, Indian, and Others (like Hispanic, Latino, Middle Eastern) <br> <b>not my choice of language - terms from original site.</b></li>\n",
    "          <li>  Each row of this version of the dataset contains integer values for the three features, a string with the name or the original jpg from the UTK archive, and a feature called 'pixels' which contains the 48x48 pixels values as a string.</li>\n",
    "    </ul>\n",
    "\n",
    "After some preliminaries, the next two cells load the data into a pandas dataframe and then shpw the first ten lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c738466a-1e08-4fe7-9a63-31a2e0493e82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os\n",
    "import socket\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical # convert to one-hot-encoding\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers as keras_layers\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "tf.get_logger().setLevel('ERROR')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69831a9e-c8ed-4dcd-abf3-1089557aefb7",
   "metadata": {},
   "source": [
    "## Some constants to keep experiments the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93a13eb7-bec1-4d7f-8677-84099a294510",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batchsize=50\n",
    "max_epochs=100\n",
    "num_imgs=1000\n",
    "patience=5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4fe445-48c0-430c-9e51-4561095d1a72",
   "metadata": {},
   "source": [
    "## Define useful method to plot training history and confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c516fb73-d8b0-4bfc-b159-6339c67ce19a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def report(history,y_pred,y_true):\n",
    "    plt.plot(history.epoch, history.history[\"accuracy\"],history.history['val_accuracy'])\n",
    "    plt.xlabel('epochs')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.suptitle('Training (blue) and validation (orange) History')\n",
    "    plt.show()\n",
    "    \n",
    "    predicted= np.argmax(y_pred,axis=1)\n",
    "    actual = np.argmax(y_true,axis=1)\n",
    "    print(f'Test Accuracy {(predicted==actual).sum() *100/len(actual)}%')\n",
    "    cm=ConfusionMatrixDisplay.from_predictions(actual,predicted,display_labels=['male','female']) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c39c83-c741-4850-b536-4cbd53286beb",
   "metadata": {},
   "source": [
    "# Get the face data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cc2b077-95be-4799-aaa1-97608f426e88",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['age', 'ethnicity', 'gender', 'img_name', 'pixels', 'label'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "if (socket.gethostname()=='csctcloud'): #on csctcloud\n",
    "    datapath=\"/home/common/datasets\"\n",
    "elif (socket.gethostname()[0:7]=='jupyter'): #on csctcloud\n",
    "    datapath=\"~/shared/datasets\"\n",
    "else: #machine specific- this is for jim's development\n",
    "    datapath = \"../datasets\"\n",
    "dataframe = pd.read_csv(datapath+'/utk/teacher_pupil.csv')\n",
    "dataframe.head()\n",
    "print(dataframe.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11459d9e-8893-4d63-9a8d-d9b13418b2d6",
   "metadata": {},
   "source": [
    "### Let's start by splitting the images into appropriate numpy arrays\n",
    "- We first convert the 'pixels' column of the dataframe into a numpy array\n",
    "- then split each row into a sub-array using a space as a seperator, \n",
    "- before reshaping our array from 23705x2304 floats into 23705 * (48x48) images\n",
    "- the conversion of the labels is first makes a straightforward 1d array, \n",
    "  then uses that to put 1s into the right column of a 2d array for one-hot encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0816f1-f700-475c-8d75-c3e27eb93d93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "imgs = dataframe['pixels'].to_numpy()\n",
    "print(f'original shape of imgs array {imgs.shape}')\n",
    "imgs = np.array([x.split(' ') for x in imgs], dtype=float)\n",
    "print(f' shape  after splitting: {imgs.shape}')\n",
    "imgs = imgs.reshape(-1,48,48,1).astype(int)\n",
    "print(f'shape  after reshaping into 2d images with one channel: {imgs.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1d87d5-1d3f-4de6-ba85-4e7058cee687",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "labels= dataframe['gender'].to_numpy()\n",
    "y = to_categorical(labels,num_classes=2)\n",
    "print(f'shape of labels is {labels.shape} and y is {y.shape}')\n",
    "print(f'Split of males:females in the labels is {np.unique(labels,return_counts=True)[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71dad04-1587-4c45-89b0-23b5c2b8a08a",
   "metadata": {},
   "source": [
    "### delete the original dataframe to save memory\n",
    "del dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9711ef0-1203-4dc9-be42-a39a612b7de0",
   "metadata": {},
   "source": [
    "### This is what ten randomly chosen images look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62704178-6fa8-484b-b631-4910771db84e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig,axs=plt.subplots(2,5,figsize=(7.5,5))\n",
    "for i in range(10):\n",
    "    img = random.randint(0,labels.shape[0])\n",
    "    axs[i//5][i%5].imshow(imgs[img].reshape(48,48),cmap='gray')\n",
    "    axs[i//5][i%5].set_title(f'{ \"male\" if labels[img]==0 else \"female\"}\\n y[i]= {y[img]}')\n",
    "                                   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d697a7-b638-448f-a2cd-c227e5487b61",
   "metadata": {},
   "source": [
    "### Finally use standard sklearn function to split data into training and test set\n",
    "\n",
    "**Note** the use of the stratify option to preserve (roughly) even distribution of males:females in train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b82d3e-45ca-4037-8690-dbc67bd99628",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "X_train,X_test,y_train,y_test= train_test_split(imgs,y,test_size=7705,shuffle=True,stratify=y)\n",
    "print('For sanity-checking: train and test arrays have shapes '\n",
    "      f'{X_train.shape}, {X_test.shape}, '\n",
    "      f'{y_train.shape},{y_test.shape}'\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d416ddd5-80a9-4a7b-b71d-537c03141c97",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Now the convnet bit\n",
    "- start by specifying  a function to create a straightforward CNN using keras sequential model interface\n",
    "- then make a model and train it\n",
    "\n",
    "The architecture is inspired by [this kaggle post](https://www.kaggle.com/code/amishaasrani/gender-detection-by-cnn).  \n",
    "It optionally introduces some new types of layer into each convolution-maxpooling block, which implement some standard tricks to improve deep networks training.\n",
    "1. *Batch normalisation* is a method that attempts to reduce the random effects of dividing the data into batches.  \n",
    "   - It works by scaling the outputs from each batch of data so they lie roughly within constant bounds  \n",
    "   estimated as the mean of the training data +/- the std. deviation of the training data.  \n",
    "   - The net effect is usually to make it **faster to train** a network.  \n",
    "   - [keras documentation here](https://keras.io/api/layers/normalization_layers/batch_normalization/)  \n",
    "   - [Machine Learning Mastery blog here](https://machinelearningmastery.com/batch-normalization-for-training-of-deep-neural-networks/)\n",
    "2. *Dropout* is a **regularisation** technique applied to try and reduce the number of variables (non-zero weights) in the learned model.  \n",
    "   It works  by effectively pruning connections.  \n",
    "   - During training a fraction (0.2 in this case) of the nodes are arbitrarily 'switched off' for each batch,  \n",
    "     so that the back-propagation can then reduce weights that do not seem to have any effect. \n",
    "   - The net effect is usually **to help prevent over-fitting**. \n",
    "   - [keras documentation here](https://keras.io/api/layers/regularization_layers/dropout/)  \n",
    "   - [Machine Learning Mastery blog here](https://machinelearningmastery.com/dropout-for-regularizing-deep-neural-networks/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce00f139-a031-4aa9-b950-52e97f3eaff7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def conv_model(num_classes,use_dropout=False,use_batch_norm=False):\n",
    "    model = Sequential()\n",
    "    \n",
    "    #first block of layers\n",
    "    model.add(keras_layers.Conv2D(32, kernel_size=(3, 3), activation='relu', padding = \"same\", input_shape=(48,48,1)))\n",
    "    if use_batch_norm:\n",
    "        model.add(keras_layers.BatchNormalization())\n",
    "    model.add(keras_layers.MaxPool2D(pool_size=(2,2)))\n",
    "    if use_dropout:\n",
    "        model.add(keras_layers.Dropout(0.2))\n",
    "    \n",
    "    #second block of layers\n",
    "    model.add(keras_layers.Conv2D(64, kernel_size=(3,3),activation=\"relu\",padding=\"same\"))\n",
    "    if use_batch_norm:\n",
    "        model.add(keras_layers.BatchNormalization())\n",
    "    model.add(keras_layers.MaxPool2D(pool_size=(2,2)))\n",
    "    if use_dropout:\n",
    "        model.add(keras_layers.Dropout(0.2))\n",
    "    \n",
    "    #third block of layers\n",
    "    model.add(keras_layers.Conv2D(64, kernel_size=(3,3),activation=\"relu\",padding=\"same\"))\n",
    "    if use_batch_norm:\n",
    "        model.add(keras_layers.BatchNormalization())\n",
    "    model.add(keras_layers.MaxPool2D(pool_size=(2,2)))\n",
    "    if use_dropout:\n",
    "        model.add(keras_layers.Dropout(0.2))\n",
    "    \n",
    "    #fully connected layers followed by softmax output\n",
    "    model.add(keras_layers.Flatten())\n",
    "    model.add(keras_layers.Dense(256,activation=\"relu\"))#256\n",
    "    model.add(keras_layers.Dense(num_classes, activation=\"softmax\"))\n",
    "    \n",
    "    model.compile(optimizer='Adam',\n",
    "              loss= 'BinaryCrossentropy',\n",
    "              metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9ea706-4ea9-47c8-9306-34a0dce953ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "convnet = conv_model(num_classes=2)\n",
    "convnet.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6eb8ae-4a3c-44b4-9b8a-bd876a8f3e57",
   "metadata": {},
   "source": [
    "### Train the model using an early stopping criteria\n",
    "\n",
    "This is another approach to try and reduce over-fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf483629-a87f-4eba-8a95-b9f80e90d958",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss',patience=patience, \n",
    "                               min_delta=0.001,\n",
    "                               restore_best_weights=True)\n",
    "\n",
    "\n",
    "history= convnet.fit(X_train,y_train,validation_split=0.1,epochs=max_epochs,batch_size=batchsize, callbacks=early_stopping,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa3e069-1bf5-48c9-91d1-26aa418809c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred= convnet.predict(X_test)\n",
    "y_true=y_test\n",
    "report(history,y_pred,y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b60f8e4-3bba-42fc-8b8f-7333c4f98c2f",
   "metadata": {},
   "source": [
    "### You should get ~87% test accuracy using a 16000:7350 data split - not bad for a small convnet and ~10 iterations\n",
    "## But what if we had fewer samples?\n",
    "\n",
    "- say 500  in total\n",
    "- and we use 20% for testing\n",
    "- and 10% for validation  to do early stopping\n",
    "\n",
    "We'll use the sklearn train_test_split() method to make sure the male/female mix in our subset is roughly the same as in our original data\n",
    "\n",
    "***and we'll do some memory cleaning along the way***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8b3320-c500-43ed-a33f-2d7fede13814",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#delete the bigger Xtrain test etc\n",
    "del X_train,X_test,y_train,y_test\n",
    "\n",
    "#num_imgs=500\n",
    "seed = 12345\n",
    "_, img_subset,_,label_subset= train_test_split(imgs,y,\n",
    "                                               test_size=num_imgs,\n",
    "                                               shuffle=True,stratify=y,\n",
    "                                               random_state=seed)\n",
    "X_train,X_test,y_train,y_test= train_test_split(img_subset,label_subset,\n",
    "                                                test_size=0.2,\n",
    "                                                shuffle=True,stratify=label_subset,\n",
    "                                                random_state=seed)\n",
    "print(f'gender split in training subset {np.unique(y_train[:,0].astype(int),return_counts=True)[1]}')\n",
    "print(f'gender split in test subset {np.unique(y_test[:,0].astype(int),return_counts=True)[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878d1d7f-5b9c-4d32-b225-fd6fe3049d19",
   "metadata": {},
   "source": [
    "### Retrain a new  model on this smaller dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e028e99-ef64-402c-a997-46cfe71b078a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "convnet2 = conv_model(num_classes=2)\n",
    "history= convnet2.fit(X_train,y_train,validation_split=0.125,epochs=max_epochs,batch_size=batchsize, callbacks=early_stopping,verbose=True)\n",
    "y_pred= convnet2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efebf840-f322-4536-b26c-195d8f3f95fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "report(history,y_pred,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac4b24f-999a-4163-af1a-c7add44d1fb9",
   "metadata": {},
   "source": [
    "### you'll probably see about a twenty percent reduction in mean accuracy, \n",
    "- and the accuracy for females is affected most\n",
    "\n",
    "### Note also that early stopping kicks in around 14 epochs, \n",
    "- but accuracy is starting to flatline\n",
    "- in my experiments it  changing patience to 10 only ran for ~5 more epochs and did not affect accuracy "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e1d092-9c4a-4d22-bae7-12311e28c35b",
   "metadata": {},
   "source": [
    "## Keras Support for data augmentation\n",
    "There is a list of preprocessing layers, including data augmentation, and different ways of using them in a workflow in [this Keras guide](https://keras.io/guides/preprocessing_layers/).\n",
    "\n",
    "For now we will begin by illustrating the effects of some common functions\n",
    " - **look up what the parameters mean** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e69a27bc-2d48-4b72-abea-525929ffb655",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_augmentation = [Sequential(keras_layers.RandomFlip(mode='horizontal')),\n",
    "                     Sequential(keras_layers.RandomContrast(1)), \n",
    "                     Sequential(keras_layers.RandomRotation(0.05)),\n",
    "                     Sequential(keras_layers.RandomZoom(0.5)),\n",
    "                     Sequential(keras_layers.RandomTranslation(0.1,0.1))]\n",
    "names=['flip','contrast','rotation','zoom','translate']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6209c5f4-2f71-4b6b-ad33-58f9bd0af62f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig,axs= plt.subplots(len(names),5,figsize=(10, 10))\n",
    "first_image = X_train[0]\n",
    "for row in range(len(names)):\n",
    "    axs[row][0].set_ylabel(names[row])\n",
    "    for col in range(5):\n",
    "        augmented_image = data_augmentation[row](\n",
    "        tf.expand_dims(first_image, 0), training=True\n",
    "        )\n",
    "        axs[row][col].imshow(augmented_image[0].numpy().astype(\"int32\"),cmap='gray')\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8118c7-e63a-444b-a83c-06c84cd225f7",
   "metadata": {},
   "source": [
    "# so now to create a pipeline that will be used in training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5bf675-a3d8-403f-a449-de470032671c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_gender_face_data(seed=12345,num_imgs=1000):\n",
    "    if (socket.gethostname()=='csctcloud'): #on csctcloud\n",
    "        datapath=\"/home/common/datasets\"\n",
    "    elif (socket.gethostname()[0:7]=='jupyter'): #on csctcloud\n",
    "        datapath=\"~/shared/datasets\"\n",
    "    else: #machine specific- this is for jim's development\n",
    "        datapath = \"../datasets\"\n",
    "    dataframe = pd.read_csv(datapath+'/utk/teacher_pupil.csv')\n",
    "    \n",
    "    imgs = dataframe['pixels'].to_numpy()\n",
    "    imgs = np.array([x.split(' ') for x in imgs], dtype=float)\n",
    "    imgs = imgs.reshape(-1,48,48,1).astype(int)\n",
    "    labels= dataframe['gender'].to_numpy()\n",
    "    del dataframe\n",
    "    y = to_categorical(labels,num_classes=2)\n",
    "    \n",
    "    _, img_subset,_,label_subset= train_test_split(imgs,y,\n",
    "                                                   test_size=num_imgs,\n",
    "                                                   shuffle=True,\n",
    "                                                   stratify=y,\n",
    "                                                   random_state=seed)\n",
    "    X_train,X_test,y_train,y_test= train_test_split(img_subset,label_subset,\n",
    "                                                    test_size=0.2,\n",
    "                                                    shuffle=True,\n",
    "                                                    stratify=label_subset,\n",
    "                                                    random_state=seed)\n",
    "    print(f'gender split in training subset {np.unique(y_train[:,0].astype(int),return_counts=True)[1]}')\n",
    "    print(f'gender split in test subset {np.unique(y_test[:,0].astype(int),return_counts=True)[1]}')\n",
    "\n",
    "    return X_train,X_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9543338d-5c53-4411-a189-c8e90db755f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# make a function that will let us choose which augementations to use\n",
    "def make_augmenter(flip=True,\n",
    "                   contrast=True,\n",
    "                   rotation=True,\n",
    "                   zoom=True,\n",
    "                   translation=True):\n",
    "    augmenter = Sequential()\n",
    "    #add 'do-nothing' layer in case rest are all false\n",
    "    augmenter.add(keras_layers.Lambda(lambda x: x))\n",
    "    #\n",
    "    if flip:\n",
    "        print('adding random flip')\n",
    "        augmenter.add(keras_layers.RandomFlip(mode='horizontal'))\n",
    "    if contrast:\n",
    "        print('adding random contrast')\n",
    "        augmenter.add(keras_layers.RandomContrast(1))\n",
    "    if rotation:\n",
    "        print('adding random rotation')\n",
    "        augmenter.add(keras_layers.RandomRotation(0.05))\n",
    "    if zoom:\n",
    "        print('adding random zoom')\n",
    "        augmenter.add(keras_layers.RandomZoom(0.5))\n",
    "    if translation:\n",
    "        print('adding random translation')\n",
    "        augmenter.add(keras_layers.RandomTranslation(0.1,0.1))\n",
    "    return augmenter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aed861f-02e5-4891-b59b-916ea3422d7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a tf.data pipeline of augmented images (and their labels)\n",
    "#this time we have to take out the validation set manually\n",
    "\n",
    "def get_augmented_data_streams(X_train,y_train,\n",
    "                               batchsize,\n",
    "                               data_augmentation,\n",
    "                               valsplit=0.1):\n",
    "    \n",
    "    #get sizes of data- note we rely on it having been shuffled\n",
    "    split=int(X_train.shape[0] * (1.0-valsplit))\n",
    "    valsize= int(X_train.shape[0]*valsplit)\n",
    "    assert  split+valsize ==len(y_train),f\"can't split data we don't have {len(y_train)}\"\n",
    "    #then split it up\n",
    "    x_tr= X_train[:split,:]\n",
    "    y_tr=y_train[:split]\n",
    "    x_val= X_train[split:split+valsize,:]\n",
    "    y_val=y_train[split:split+valsize]\n",
    "    assert split%batchsize==0,f\"training set size {split} must be multiple of batchsize{batchsize}\"\n",
    "    assert valsize%batchsize==0,\"validation set size must be multiple of batchsize\"\n",
    "\n",
    "    #this is straigthforward but uses tensorflow data objects\n",
    "    validation_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "    validation_dataset = validation_dataset.batch(batchsize)\n",
    "\n",
    "    #training dataset gets augmented after being split into batches\n",
    "    # using the dataset.map function\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((x_tr, y_tr))\n",
    "    train_dataset=train_dataset.shuffle(1000)\n",
    "    train_dataset=train_dataset.batch(batchsize)\n",
    "    train_dataset = train_dataset.map(lambda x, y: (data_augmentation(x,training=True), y))\n",
    "    \n",
    "    return train_dataset,validation_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3d0300-c206-4500-a439-4f1be9d008d7",
   "metadata": {},
   "source": [
    "### Now put all the pieces together into a function that can be called in a loop \n",
    "Note the only difference is that you might want to increase the patience \n",
    "- because we are using different training data each epoch\n",
    "- so that naturally creates more variability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db0351e-3603-48fa-a077-fc73a274aa92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_experiment (flip=False,contrast=False,rotation=False,zoom=False,translation=False,\n",
    "                    batchsize=50,num_imgs=num_imgs,\n",
    "                    valsplit=0.125,patience=10):\n",
    "    \n",
    "    # run data through the pipeline we have created\n",
    "    X_train,X_test,y_train,y_test = get_gender_face_data(num_imgs=num_imgs)\n",
    "    data_augmentation= make_augmenter(flip=flip,contrast=contrast,\n",
    "                                      rotation=rotation,zoom=zoom,translation=translation)\n",
    "    train_dataset,val_dataset = get_augmented_data_streams(X_train,y_train, \n",
    "                                                           batchsize,data_augmentation,\n",
    "                                                           valsplit=valsplit)\n",
    "    \n",
    "    num_train_samples= int(X_train.shape[0] * (1.0-valsplit))\n",
    "    print(f'Data made with {num_train_samples} training examples')\n",
    "    \n",
    "    # use our defintion of a conv model\n",
    "    augmented_cnn = conv_model(num_classes=2)\n",
    "    early_stopping = EarlyStopping(monitor='val_loss',patience=patience, \n",
    "                               min_delta=0.001,\n",
    "                               mode='min',\n",
    "                               restore_best_weights=True)\n",
    "    history= augmented_cnn.fit(train_dataset,\n",
    "                               steps_per_epoch=num_train_samples/batchsize,\n",
    "                               epochs=max_epochs,\n",
    "                               batch_size=batchsize,\n",
    "                               validation_data=val_dataset, \n",
    "                               callbacks=early_stopping,\n",
    "                               verbose=True)\n",
    "\n",
    "    y_pred = augmented_cnn.predict(X_test,verbose=0)\n",
    "    return history, y_pred,y_test\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d714a014-b252-4bc0-92a8-2ada59fb343a",
   "metadata": {},
   "source": [
    "## Now we can run our first experiment using data augmentation\n",
    " - run it once with everything off, \n",
    " - this is the same setup as we had before so you should get 65% - 70% test accuracy\n",
    " - then try turning all the different augmenters on and see how that does  \n",
    "   **Hint** the accuracy will fluctuate more so you might want to increase the patience from 5 to 10 or 20  \n",
    "   **Hint2** depending on what you call a 'fair' comparison, you could also increase max_epochs \n",
    "   from the default of 100 we used above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea9e88b-a832-421e-8421-6ec3f7a6b55e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#this runs an experiment\n",
    "#with nothing set to be true this is just a replication of the original convnet training\n",
    "\n",
    "#reminder of what we had above\n",
    "max_epochs=100\n",
    "patience=5\n",
    "\n",
    "history,y_pred,y_true= run_experiment(translation=False,\n",
    "                                      rotation=False,\n",
    "                                      flip=False,\n",
    "                                      contrast=False,\n",
    "                                      zoom=False,\n",
    "                                      num_imgs=num_imgs,\n",
    "                                      batchsize=batchsize,\n",
    "                                      patience=patience)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edee27f-cf76-4e15-a0ba-d0891e32419b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "report(history,y_pred,y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c236e6-4b38-49a6-bdff-6670f5269651",
   "metadata": {},
   "source": [
    "## You should see that now the training accuracy is actually often lower than the validation accuracy\n",
    "\n",
    "- but both are steadily increasing\n",
    "- you could change the patience value to leave it running longer\n",
    "- (but on my machine it is using quite a lot of memory)\n",
    "\n",
    "### With the right set-up you should be able to get  test accuracy quite a bit higher than without augmentation - is this significant?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95046ac3-2d88-42bf-91fc-a189404b0362",
   "metadata": {},
   "source": [
    "# Questions to investigate:\n",
    "1. What is the effect of the random sampling even with no transformations?  \n",
    "   Try setting all the options to False and do a few train/test runs\n",
    "2. Which of these are valid and useful transformations for human faces?:\n",
    " - translation (horizontal/vertical) shifts\n",
    " - rotation\n",
    " - horizontal flips\n",
    " - vertical flips\n",
    " \n",
    "Do you think it would  make a difference what the task is, i.e. gender recognition vs. recognising a specific person?\n",
    " \n",
    "To do this investigation using appropriate scientific method, treat each of these as a hypothesis to be tested. Take a number of observations (e.g. accuracy of trained model) for each case (e.g. using horizontal flips vs not using horizontal flips) then compare the mean results and use appropriate statistcal tests to determine whether the results are statistically significantly different."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f66cd00-3f13-44fb-b9f2-233dd19ad0ec",
   "metadata": {},
   "source": [
    "# The main task:\n",
    "\n",
    "- Use the different pipeline components above to experiment with different sorts of data augmenation available within keras e.g. rotations, zoom,contrast changes,  and vertical/ horizontal flips. There are others available that only require a minor extension to my make_augmenter() function.\n",
    "- Design an appropriate methodology to evaluate what difference they make singly or in combination to the classification accuracy of the trained system?  \n",
    "  *Hint*: If you are making several changes to a system you need some way of knowing which have had an effect: [illustrated in 200 words](https://thaddeus-segura.com/data-aug/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e5ab97-b8d3-416d-aa04-e9d1bb9dadfd",
   "metadata": {},
   "source": [
    "## The second task:\n",
    "In the basic method definition of a CNN we had batch normalisation and dropout turned off.  \n",
    "Try changing the code to see what the effect of the other approaches for reducing over-fitting are in combination with the data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc067e9-9380-49a2-92dd-cf9c6892a910",
   "metadata": {},
   "source": [
    "## The third task:\n",
    "The approach I used above creates a set of keras layers and pre-processes the data **outside** the model.\n",
    " - it is **option 2** in [this blog](https://www.tensorflow.org/tutorials/images/data_augmentation)\n",
    " - the alternative is to make the augmentation (or other preprocessing layers) part of your model. \n",
    "   described as option 1 in the blog.\n",
    "\n",
    "To give you more familiarity with working with keras layers, try adapting the convnet() method to put the data augmentation layers inside the model  and see:\n",
    "- does it affect training speed\n",
    "- does it affect predictive accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44f3646-6c0d-49aa-9e28-6bfeb87c9572",
   "metadata": {},
   "source": [
    "### class discussion\n",
    "does data augmentation provide a way of addressing:\n",
    "- ethical concerns about under-representation of certain groups\n",
    "- safety concerns for example wrt autonomous vehicles\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920111a8-07f4-4130-b585-fd44e86f6d42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
