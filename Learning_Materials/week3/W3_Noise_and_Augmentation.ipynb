{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1160a414-5637-457f-8ee3-05d165ef19d3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Week 3: Noise, Bias and Augmentation \n",
    "\n",
    "This week is all about looking at the practicalities of collecting data from the 'real world'\n",
    "- thinking about 'sanity-checking' what we are  given\n",
    "- thinking about how there might be biases in what we are given\n",
    "- thinking about how there might be 'gaps' in what we are given\n",
    "\n",
    "and how to deal with these."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02ad90c-346e-42ea-8206-1f7d371bc1e1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Example: revisiting the Palmer Penguins Dataset\n",
    "\n",
    "This data has 344 records and seven features:\n",
    "- Species (use this as the label to be predicted)\n",
    "- Island\n",
    "- culmen_length_mm\n",
    "- culmen_depth_mm\n",
    "- flipper_length_mm\n",
    "- body_mass_g\n",
    "- sex\n",
    "and this is what they look like\n",
    "\n",
    "We can remind ourselves what the data set is like by looking at the [kaggle page](https://www.kaggle.com/datasets/parulpandey/palmer-archipelago-antarctica-penguin-data?resource=download&select=penguins_size.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c031ec2-5a5a-4a99-b9ff-8ae38101038e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "And this description is taken from  the original paper:\n",
    "\n",
    "Each season, study nests, where pairs of adults were present, were individually marked and chosen before the onset of egg laying, and consistently monitored. When study nests were found at the one-egg stage, **both adults were captured** to obtain blood samples used for molecular sexing and SI analyses, and measurements of structural size and body mass. **At the time of capture, each adult penguin was quickly blood sampled** (∼1 ml) from the brachial vein using a sterile 3 ml syringe and heparinized infusion needle. Collected blood was stored in 1.5 ml micro-centrifuge tubes that were kept cool. In the field, a small amount of whole blood was smeared on clean filter paper stored in a 1.5 ml micro-centrifuge tube for molecular sexing. **Measurements of culmen length and depth (using dial calipers ±0.1 mm), right flipper (using a ruler ±1 mm), and body mass (using 5 kg±25 g or 10 kg±50 g Pesola spring scales and a weigh bag) were obtained to quantify body size variation**. After handling, individuals at study nests were further monitored to ensure the pair reached clutch completion, i.e., two eggs.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Gorman KB, Williams TD, Fraser WR (2014). Ecological sexual dimorphism and environmental variability within a community of Antarctic penguins (genus Pygoscelis). PLoS ONE 9(3):e90081. https://doi.org/10.1371/journal.pone.0090081"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24c11aa-ad02-41ff-bc0a-e0586c3589f9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-block alert-warning\" style=\"width:400px, text-color:black\">     \n",
    "    <h3>How accurately do you think you could measure a struggling penguin?</h3>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8136778e-1239-4d4c-b557-698ad31ce45f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Another example: A medical dataset\n",
    "Anonymised patient records and how long they survived\n",
    "\n",
    "\n",
    "_citation_:\n",
    "Raffa, J. (2016). Clinical data from the MIMIC-II database for a case study on indwelling arterial catheters (version 1.0). PhysioNet. https://doi.org/10.13026/C2NC7F.\n",
    "\n",
    "Raffa J.D., Ghassemi M., Naumann T., Feng M., Hsu D. (2016) Data Analysis. In: Secondary Analysis of Electronic Health Records. Springer, Cham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb558772-73ed-443a-aa62-643ec826c223",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "socket hostname is S-FET-QW50CYWDHW\n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "import pandas as pd\n",
    "\n",
    "thehost=socket.gethostname()\n",
    "print(f'socket hostname is {thehost}')\n",
    "if (socket.gethostname()=='csctcloud'): #on csctcloud\n",
    "    datapath=\"/home/common/datasets\"\n",
    "elif (thehost[0:7]=='jupyter'): #on csctcloud\n",
    "    datapath=\"~/shared/datasets\"\n",
    "else: #machine specific- this is for jim's development\n",
    "    datapath = \"../datasets\"\n",
    "    \n",
    "\n",
    "mimic= pd.read_csv(datapath +\"/mimic/mimic_iaccd_full_cohort_data_head.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b159298-bb73-4392-8f3d-1463b2ce65b6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>full_cohort_data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aline_flg</th>\n",
       "      <th>icu_los_day</th>\n",
       "      <th>hospital_los_day</th>\n",
       "      <th>age</th>\n",
       "      <th>gender_num</th>\n",
       "      <th>weight_first</th>\n",
       "      <th>bmi</th>\n",
       "      <th>sapsi_first</th>\n",
       "      <th>sofa_first</th>\n",
       "      <th>service_unit</th>\n",
       "      <th>service_num</th>\n",
       "      <th>day_icu_intime</th>\n",
       "      <th>day_icu_intime_num</th>\n",
       "      <th>hour_icu_intime</th>\n",
       "      <th>hosp_exp_flg</th>\n",
       "      <th>icu_exp_flg</th>\n",
       "      <th>day_28_flg</th>\n",
       "      <th>mort_day_censored</th>\n",
       "      <th>censor_flg</th>\n",
       "      <th>sepsis_flg</th>\n",
       "      <th>chf_flg</th>\n",
       "      <th>afib_flg</th>\n",
       "      <th>renal_flg</th>\n",
       "      <th>liver_flg</th>\n",
       "      <th>copd_flg</th>\n",
       "      <th>cad_flg</th>\n",
       "      <th>stroke_flg</th>\n",
       "      <th>mal_flg</th>\n",
       "      <th>resp_flg</th>\n",
       "      <th>map_1st</th>\n",
       "      <th>hr_1st</th>\n",
       "      <th>temp_1st</th>\n",
       "      <th>spo2_1st</th>\n",
       "      <th>abg_count</th>\n",
       "      <th>wbc_first</th>\n",
       "      <th>hgb_first</th>\n",
       "      <th>platelet_first</th>\n",
       "      <th>sodium_first</th>\n",
       "      <th>potassium_first</th>\n",
       "      <th>tco2_first</th>\n",
       "      <th>chloride_first</th>\n",
       "      <th>bun_first</th>\n",
       "      <th>creatinine_first</th>\n",
       "      <th>po2_first</th>\n",
       "      <th>pco2_first</th>\n",
       "      <td>iv_day_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>7.63</th>\n",
       "      <th>13</th>\n",
       "      <th>72.36841</th>\n",
       "      <th>1</th>\n",
       "      <th>75</th>\n",
       "      <th>29.91279129</th>\n",
       "      <th>15</th>\n",
       "      <th>9</th>\n",
       "      <th>SICU</th>\n",
       "      <th>1</th>\n",
       "      <th>Friday</th>\n",
       "      <th>6</th>\n",
       "      <th>6</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>11.92</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>92</th>\n",
       "      <th>86</th>\n",
       "      <th>95.90000153</th>\n",
       "      <th>100</th>\n",
       "      <th>22</th>\n",
       "      <th>8.1</th>\n",
       "      <th>14.1</th>\n",
       "      <th>354</th>\n",
       "      <th>138</th>\n",
       "      <th>4.6</th>\n",
       "      <th>15</th>\n",
       "      <th>109</th>\n",
       "      <th>41</th>\n",
       "      <th>1.6</th>\n",
       "      <th>196</th>\n",
       "      <th>39</th>\n",
       "      <td>2230.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>1.14</th>\n",
       "      <th>1</th>\n",
       "      <th>64.92076</th>\n",
       "      <th>0</th>\n",
       "      <th>55</th>\n",
       "      <th>20.12131169</th>\n",
       "      <th>NaN</th>\n",
       "      <th>5</th>\n",
       "      <th>MICU</th>\n",
       "      <th>0</th>\n",
       "      <th>Saturday</th>\n",
       "      <th>7</th>\n",
       "      <th>17</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>731</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>86.66670227</th>\n",
       "      <th>85</th>\n",
       "      <th>97.59999847</th>\n",
       "      <th>100</th>\n",
       "      <th>1</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.86</th>\n",
       "      <th>5</th>\n",
       "      <th>36.5</th>\n",
       "      <th>0</th>\n",
       "      <th>70</th>\n",
       "      <th>27.11827188</th>\n",
       "      <th>16</th>\n",
       "      <th>5</th>\n",
       "      <th>MICU</th>\n",
       "      <th>0</th>\n",
       "      <th>Friday</th>\n",
       "      <th>6</th>\n",
       "      <th>3</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>731</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>69.66670227</th>\n",
       "      <th>135</th>\n",
       "      <th>96.30000305</th>\n",
       "      <th>99</th>\n",
       "      <th>3</th>\n",
       "      <th>27</th>\n",
       "      <th>13.1</th>\n",
       "      <th>295</th>\n",
       "      <th>144</th>\n",
       "      <th>3.9</th>\n",
       "      <th>17</th>\n",
       "      <th>101</th>\n",
       "      <th>16</th>\n",
       "      <th>0.8</th>\n",
       "      <th>298</th>\n",
       "      <th>30</th>\n",
       "      <td>2086.800293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>0.58</th>\n",
       "      <th>3</th>\n",
       "      <th>44.49191</th>\n",
       "      <th>0</th>\n",
       "      <th>NaN</th>\n",
       "      <th>NaN</th>\n",
       "      <th>21</th>\n",
       "      <th>7</th>\n",
       "      <th>SICU</th>\n",
       "      <th>1</th>\n",
       "      <th>Saturday</th>\n",
       "      <th>7</th>\n",
       "      <th>4</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <th>101</th>\n",
       "      <th>125</th>\n",
       "      <th>100.0999985</th>\n",
       "      <th>100</th>\n",
       "      <th>4</th>\n",
       "      <th>7.1</th>\n",
       "      <th>12.6</th>\n",
       "      <th>262</th>\n",
       "      <th>139</th>\n",
       "      <th>4.2</th>\n",
       "      <th>31</th>\n",
       "      <th>100</th>\n",
       "      <th>16</th>\n",
       "      <th>0.5</th>\n",
       "      <th>146</th>\n",
       "      <th>23</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                full_cohort_data\n",
       "aline_flg icu_los_day hospital_los_day age      gender_num weight_first bmi         sapsi_first sofa_first service_unit service_num day_icu_intime day_icu_intime_num hour_icu_intime hosp_exp_flg icu_exp_flg day_28_flg mort_day_censored censor_flg sepsis_flg chf_flg afib_flg renal_flg liver_flg copd_flg cad_flg stroke_flg mal_flg resp_flg map_1st     hr_1st temp_1st    spo2_1st abg_count wbc_first hgb_first platelet_first sodium_first potassium_first tco2_first chloride_first bun_first creatinine_first po2_first pco2_first         iv_day_1\n",
       "1         7.63        13               72.36841 1          75           29.91279129 15          9          SICU         1           Friday         6                  6               1            0           1          11.92             0          0          0       0        0         0         0        0       0          1       0        92          86     95.90000153 100      22        8.1       14.1      354            138          4.6             15         109            41        1.6              196       39                 2230.875\n",
       "0         1.14        1                64.92076 0          55           20.12131169 NaN         5          MICU         0           Saturday       7                  17              0            0           0          731               1          0          0       0        0         0         0        0       0          0       0        86.66670227 85     97.59999847 100      1         NaN       NaN       NaN            NaN          NaN             NaN        NaN            NaN       NaN              NaN       NaN                     600\n",
       "          2.86        5                36.5     0          70           27.11827188 16          5          MICU         0           Friday         6                  3               0            0           0          731               1          0          0       0        0         0         0        0       0          0       0        69.66670227 135    96.30000305 99       3         27        13.1      295            144          3.9             17         101            16        0.8              298       30              2086.800293\n",
       "1         0.58        3                44.49191 0          NaN          NaN         21          7          SICU         1           Saturday       7                  4               1            1           1          0                 0          0          0       0        0         0         0        0       0          1       0        101         125    100.0999985 100      4         7.1       12.6      262            139          4.2             31         100            16        0.5              146       23                      NaN"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mimic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7c7883-f778-44b1-b358-d87b8c001284",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "From [this NHS website](https://www.nhs.uk/common-health-questions/lifestyle/what-is-the-body-mass-index-bmi/)\n",
    "\n",
    "The body mass index (BMI) is a measure that uses your height and weight to work out if your weight is healthy.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\" style=\"width:400px, text-color:black\">The BMI calculation divides an adult's weight in kilograms by their height in metres squared. \n",
    "</div>    For example, A BMI of 25 means 25kg/m2.\n",
    "     \n",
    "### How reasonable are the BMI values above?\n",
    "- how much do you think they might vary during the day?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d52f975-0a67-44b2-82fa-4a5e5468b039",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## The first take-home message: you can't always trust what you are told! \n",
    "You need to ask yourself:\n",
    "- what determines the right precision for numerical values? the device or how it is used?\n",
    "- rule of thumb for calculations: report to precision of least accurate part of calculation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c7c50d-68c0-43a3-90b1-0c19d4ea3782",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Second Take-Home Message: \n",
    "## Taking a measurement/image/... repeatedly may give different results\n",
    "- time of day for weight\n",
    "- slight changes in lighting, camera angle/position, dirty lens\n",
    "- varying background noise in sound recordings\n",
    "- people get pay rises ...\n",
    "\n",
    "But can we exploit this?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92467d15-398a-4bfa-ad18-9b2063b885a3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Sources of Noise/ variation/ uncertainty in datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d0ad29-494a-440f-96c1-eea9f8e4e3b0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Source 1: How we sample items from the underlying distribution of things (the 'world') to measure\n",
    " - Does distribution of items we select match the underlying distribution  \n",
    "   e.g. are we sampling from hospital patients, who may be more likely to have a disease  \n",
    " - Do we need to take country/geography /spatial factors into account       \n",
    " - Is  the distribution of types of things in the world is changing over time  \n",
    "   e.g. proportion of people testing positive for a disease \n",
    " - Are the measurements for different subsets of data are changing over time.   \n",
    "   e.g. different variants of a disease with slightly different symptoms  \n",
    "    cars getting heavier (electric batteries)\n",
    "    different groups of people living longer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758449db-c258-4721-90e6-0d61d7ce2fd8",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "   \n",
    " **These are potential sources of unethical/ unwanted bias in our samples**  \n",
    "   We may be able to deal with these using things like Generative Adversarial Networks\n",
    "   - there's **lots** of work on using GANs to generate data for training autonmous vehicles\n",
    "   - although [a recent paper](https://www.sciencedirect.com/science/article/pii/S0004370221002034#se0060) suggest this may be problematic when it comes to addressing bias around human records and images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43cb16fd-c6ee-42fe-a7c1-7a924975cff5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "**Law and Ethics** \n",
    "The Information Commissioner's Office [AI and Data Protection Risk Toolkit](https://ico.org.uk/for-organisations/uk-gdpr-guidance-and-resources/artificial-intelligence/guidance-on-ai-and-data-protection/ai-and-data-protection-risk-toolkit/) \n",
    "- applies to anyone working in the UK and training a model on people's data \n",
    "- lays clear obligations to\n",
    "  - assess risk that AI disadvantages people according to protected characteristics\n",
    "  - measure risk of 'privacy leakage' (more on this another week)\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfcb752-6f32-4d83-b917-e502d2df7fc3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Source 2: How we measure/capture/represent the samples we take to create a dataset\n",
    " - If can identify valid transformations we may be able use these to generalise  \n",
    "   **e.g. Data Augmentation = today's practical** \n",
    "   \n",
    "   Question: Is this a link between 'computational AI' and semantics?\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79bb6fba-53b0-4068-a67d-502f98a73db1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Source 3: How we divide our dataset into training, validation and test sets\n",
    " - This is why we should use techniques like N-fold cross validation if we have limited data\n",
    " - There is ongoing debate in the ML community about whether it is better to do, for example,  \n",
    "   one set of 10-fold cross validation (i.e. split data into ten parts randomly once),  \n",
    "   or 5 X 2-fold cross-validation ( 5 repeats of randomised equal-sized train-test splits)\n",
    "  - A single train/test split is not adequate unless you have **lots** of **representative** data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d43e50-89ce-45f7-800e-0d5982ae0f63",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "## and then on top of that ...\n",
    "### Source 4: the variation that comes with some ML algorithms\n",
    "- random weight initialisation\n",
    "- stochastic routines in (for example) evolving trees (Genetic Programming), or Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c54f68a-5685-4d3b-abc1-ac6c8bc52c60",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# So what is data augmentation all about?\n",
    "\n",
    "1. Come up with some valid transformations for your data\n",
    "  - adding noise to measurements\n",
    "  - accounting for different camera positions / lighting\n",
    "  - using synonyms in text\n",
    "  - changing background noise in images or sound\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deadcfaf-fa09-4e81-aee0-3684e76c5421",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "2. Apply the transformations to copies of your existing labelled data to make more examples   \n",
    "  (keeping the labels the same)  \n",
    "   Either use them to generate:\n",
    "     - a fixed extra set of more training examples \n",
    "     - new items for each epoch of training (obviously  Neural Nets only)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8713805d-13e5-416d-9d7b-11593145441d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "3. train with the extra data (or data generators) in the hope of reducing over-fitting   \n",
    "  by taking account of the 'measurement' effect from above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a39b36-e86e-43bb-a13c-d47532810e2e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Possible problems?\n",
    "\n",
    "- can replicate existing bias in the way we sample things to measure/represent\n",
    "- what if your samples were outliers?  \n",
    "  adding perturbations might take you even further from 'normal' \n",
    "  \n",
    "-   What do we mean by 'valid'? who gets to decide?\n",
    "  \n",
    "Good discussion of pros and cons for different types of data in [this blog](https://www.datacamp.com/tutorial/complete-guide-data-augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aeb5c65-e914-4572-a7e9-2a11e1a4940c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
